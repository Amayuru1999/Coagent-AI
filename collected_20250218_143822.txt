
# File: .//extract_project.py
import os
import argparse
import datetime

# Directories and files to ignore
IGNORED_DIRS = {"node_modules", ".git", ".idea", "__pycache__", "venv", ".venv", "dist", "build", "coverage"}
IGNORED_FILES_EXACT = {"README.md", ".gitignore", "extract_project.py", "requirements.txt", "poetry.lock"}
IGNORED_FILES_PARTIAL = {"collected_"}  # Any file starting with 'collected_'
IGNORED_EXTENSIONS = {".png", ".jpg", ".jpeg", ".gif", ".mp4", ".zip", ".tar.gz", ".whl", ".exe", ".pdf"}

# Configurations
MAX_WORDS_PER_CHUNK = 8000  # Chunking for large text files

# Argument parsing
parser = argparse.ArgumentParser(description="Extract project files into a text file.")
parser.add_argument("directory", nargs="?", default=".", help="Directory to extract files from.")
parser.add_argument("-r", "--recursive", action="store_true", help="Enable recursive search.")
parser.add_argument("-f", "--filter", type=str, default="", help="Filter files by extension (e.g., 'py', 'ts').")
args = parser.parse_args()

# Generate output filename
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
output_file = f"project_extracted_{timestamp}.txt"

# Function to check if a file should be ignored
def should_ignore(file_name, file_ext):
    if file_name in IGNORED_FILES_EXACT or file_ext in IGNORED_EXTENSIONS:
        return True
    if any(file_name.startswith(prefix) for prefix in IGNORED_FILES_PARTIAL):
        return True
    return False

# Function to recursively find files
def find_files(directory, recursive, file_extension):
    collected_files = []
    for root, dirs, files in os.walk(directory):
        # Skip ignored directories
        dirs[:] = [d for d in dirs if d not in IGNORED_DIRS]

        for file in files:
            file_ext = os.path.splitext(file)[1]
            if should_ignore(file, file_ext):
                print(f"Ignored: {file}")
                continue

            # Filter by extension if specified
            if file_extension and not file.endswith(f".{file_extension.lstrip('.')}"):
                continue

            collected_files.append(os.path.join(root, file))

        if not recursive:
            break

    return collected_files

# Function to append files to output
def append_files_to_output(file_list, output_file):
    word_count = 0
    current_chunk = 1

    with open(output_file, "w", encoding="utf-8") as out_file:
        for file in file_list:
            try:
                with open(file, "r", encoding="utf-8", errors="ignore") as in_file:
                    content = in_file.read()

                content_word_count = len(content.split())
                if word_count + content_word_count > MAX_WORDS_PER_CHUNK:
                    out_file.write(f"\n\n============ Page Break: Chunk {current_chunk} ============\n\n")
                    print(f"============ Page Break: Chunk {current_chunk} ============\n")
                    current_chunk += 1
                    word_count = 0

                out_file.write(f"\n\n### File: {file}\n\n")
                out_file.write(content)
                word_count += content_word_count

                print(f"Processed: {file}")

            except Exception as e:
                print(f"Error reading file: {file}", e)

    print(f"\n✅ Extracted project saved to: {output_file}")

# Run script
if __name__ == "__main__":
    if not os.path.exists(args.directory):
        print("❌ Error: Directory does not exist.")
        exit(1)

    files_to_process = find_files(args.directory, args.recursive, args.filter)

    if not files_to_process:
        print("❌ No matching files found.")
        exit(1)

    append_files_to_output(files_to_process, output_file)

# File: .//tests/core/conftest.py
import asyncio
import functools
import inspect
from typing import Callable, Awaitable

import pytest

from coagent.core.types import Address, Agent, RawMessage, Channel, Subscription
from coagent.core.util import idle_loop
from coagent.runtimes.local_runtime import LocalChannel


class NopChannel(Channel):
    async def connect(self) -> None:
        pass

    async def close(self) -> None:
        pass

    async def publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> RawMessage | None:
        pass

    async def subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]],
        queue: str = "",
    ) -> Subscription:
        pass

    async def new_reply_topic(self) -> str:
        pass


@pytest.fixture
def nop_channel() -> NopChannel:
    return NopChannel()


@pytest.fixture
def local_channel() -> LocalChannel:
    return LocalChannel()


def helper_func(func):
    """A decorator to create a fixture that returns the wrapped function."""

    def wrapper():
        if inspect.iscoroutinefunction(func):

            @functools.wraps(func)
            async def run(*args, **kwargs):
                return await func(*args, **kwargs)
        else:

            @functools.wraps(func)
            def run(*args, **kwargs):
                return func(*args, **kwargs)

        return run

    return wrapper


@pytest.fixture
@helper_func
def run_agent_in_task(agent: Agent) -> asyncio.Task:
    """Run the given agent in a task."""

    async def run():
        await agent.start()
        await idle_loop()
        await agent.stop()

    return asyncio.create_task(run())


@pytest.fixture
@helper_func
async def yield_control():
    """A fixture to yield control to other coroutines."""
    await asyncio.sleep(0.000001)

# File: .//tests/core/test_agent.py
import asyncio
from typing import AsyncIterator

import pytest

from coagent.core.types import Address, Agent, Channel, RawMessage
from coagent.core.agent import BaseAgent, Context, handler
from coagent.core.exceptions import BaseError
from coagent.core.messages import Message


class Query(Message):
    pass


class Reply(Message):
    pass


class TrivialAgent(BaseAgent):
    def __init__(self, wait_s: float = 0) -> None:
        super().__init__()
        self.wait_s = wait_s

    @handler
    async def handle(self, msg: Query, ctx: Context) -> Reply:
        if self.wait_s > 0:
            await asyncio.sleep(self.wait_s)
        return Reply()


class StreamAgent(BaseAgent):
    def __init__(self, chunk_size: int = 1, wait_s: float = 0) -> None:
        super().__init__()
        self.chunk_size = chunk_size
        self.wait_s = wait_s

    @handler
    async def handle(self, msg: Query, ctx: Context) -> AsyncIterator[Reply]:
        for _ in range(self.chunk_size):
            if self.wait_s > 0:
                await asyncio.sleep(self.wait_s)
            yield Reply()


class _TestFactory:
    def __init__(self, channel: Channel, address: Address):
        self.channel = channel
        self.address = address

        self.agent = None
        self.sub = None

    async def receive(self, msg: RawMessage) -> None:
        await self.agent.stop()

    async def start(self, agent: Agent) -> None:
        self.agent = agent
        self.sub = await self.channel.subscribe(self.address, self.receive)


class TestTrivialAgent:
    @pytest.mark.asyncio
    async def test_normal(self, local_channel, run_agent_in_task, yield_control):
        agent = TrivialAgent()
        addr = Address(name="test", id="0")
        agent.init(local_channel, addr)

        _task = run_agent_in_task(agent)
        await yield_control()

        result = await local_channel.publish(
            addr, Query().encode(), request=True, probe=False
        )
        assert result.header.type == "Reply"

    @pytest.mark.asyncio
    async def test_cancel(self, local_channel, run_agent_in_task, yield_control):
        test_factory = _TestFactory(local_channel, Address(name="test_1"))

        agent = TrivialAgent(wait_s=10)
        addr = Address(name="test", id="1")
        agent.init(local_channel, addr, test_factory.address)

        await test_factory.start(agent)

        _task = run_agent_in_task(agent)
        await yield_control()

        async def cancel():
            await asyncio.sleep(0.01)
            await local_channel.cancel(addr)

        _ = asyncio.create_task(cancel())
        await yield_control()

        with pytest.raises(BaseError) as exc:
            await local_channel.publish(
                addr, Query().encode(), request=True, probe=False
            )
        assert str(exc.value).endswith("asyncio.exceptions.CancelledError\n")


class TestStreamAgent:
    @pytest.mark.asyncio
    async def test_normal(self, local_channel, run_agent_in_task, yield_control):
        agent = StreamAgent()
        addr = Address(name="test", id="2")
        agent.init(local_channel, addr)

        _task = run_agent_in_task(agent)
        await yield_control()

        result = await local_channel.publish(
            addr, Query().encode(), stream=True, probe=False
        )
        async for chunk in result:
            assert chunk.header.type == "Reply"

    @pytest.mark.asyncio
    async def test_cancel(self, local_channel, run_agent_in_task, yield_control):
        test_factory = _TestFactory(local_channel, Address(name="test_3"))

        agent = StreamAgent(wait_s=10)
        addr = Address(name="test", id="3")
        agent.init(local_channel, addr, test_factory.address)

        await test_factory.start(agent)

        _task = run_agent_in_task(agent)
        await yield_control()

        async def cancel():
            await asyncio.sleep(0.01)
            await local_channel.cancel(addr)

        _ = asyncio.create_task(cancel())
        await yield_control()

        result = await local_channel.publish(
            addr, Query().encode(), stream=True, probe=False
        )
        with pytest.raises(BaseError) as exc:
            async for _chunk in result:
                pass
        assert str(exc.value).endswith("asyncio.exceptions.CancelledError\n")

# File: .//tests/core/__init__.py

# File: .//tests/core/test_util.py
from coagent.core.util import Trie, get_func_args


class TestTrie:
    def test_direct_items(self):
        trie = Trie(separator=".")
        trie["test"] = 1
        trie["test.a"] = 2
        trie["test.b"] = 3
        trie["test.a.b"] = 4
        trie["test.a.b.c"] = 5

        assert trie.direct_items("test") == [("test", 1), ("test.a", 2), ("test.b", 3)]
        assert trie.direct_items("test.a") == [("test.a", 2), ("test.a.b", 4)]
        assert trie.direct_items("test.a.b") == [("test.a.b", 4), ("test.a.b.c", 5)]
        assert trie.direct_items("test.a.b.c") == [("test.a.b.c", 5)]


def test_get_func_args():
    def func(a: int, b: str, c: float) -> None:
        pass

    assert get_func_args(func) == {"a", "b", "c"}

# File: .//tests/core/test_discovery.py
from coagent.core.discovery import DiscoveryQuery


class TestDiscoveryQuery:
    def test_matches(self):
        # Query with empty namespace should match any name.
        query = DiscoveryQuery(namespace="")
        assert query.matches("test") is True

        # Non-inclusive mode.
        query = DiscoveryQuery(namespace="test")
        assert query.matches("test") is False

        # Inclusive mode.
        query = DiscoveryQuery(namespace="test", inclusive=True)
        assert query.matches("test") is True

        # Non-recursive mode.
        query = DiscoveryQuery(namespace="test")
        assert query.matches("test.a") is True
        assert query.matches("test.a.b") is False

        # Recursive mode.
        query = DiscoveryQuery(namespace="test", recursive=True)
        assert query.matches("test.a.b") is True

# File: .//tests/agents/conftest.py
import pytest

from coagent.agents.model_client import ModelClient


class MockModelClient(ModelClient):
    async def acompletion(
        self,
        messages: list[dict],
        model: str = "",
        stream: bool = False,
        temperature: float = 0.1,
        tools: list | None = None,
        tool_choice: str | None = None,
        response_format: dict | None = None,
        **kwargs,
    ):  # -> litellm.ModelResponse:
        if stream:
            return self._stream_response()
        else:
            return await self._non_stream_response()

    async def _non_stream_response(self):
        import litellm
        from litellm.types.utils import Choices, Message

        return litellm.ModelResponse(
            choices=[Choices(message=Message(content="hello"))]
        )

    async def _stream_response(self):
        import litellm
        from litellm.types.utils import StreamingChoices, Delta

        yield litellm.ModelResponse(
            choices=[StreamingChoices(delta=Delta(content="hello"))]
        )


@pytest.fixture
def mock_model_client() -> ModelClient:
    return MockModelClient(model="mock_model")

# File: .//tests/agents/test_chat_agent.py
from pydantic import Field
import pytest

from coagent.agents.chat_agent import wrap_error


@pytest.mark.asyncio
async def test_wrap_error():
    @wrap_error
    async def func(
        a: int = Field(..., description="Argument a"),
        b: int = Field(1, description="Argument b"),
    ) -> float:
        return a / b

    assert await func() == "Error: Missing required argument 'a'"
    assert await func(a=1) == 1
    assert await func(a=1, b=0) == "Error: division by zero"

# File: .//tests/agents/test_util.py
import pytest

from coagent.agents.util import chat


@pytest.mark.asyncio
async def test_chat(mock_model_client):
    response = await chat(
        messages=[],
        stream=False,
        client=mock_model_client,
    )
    assert response.content == "hello"


@pytest.mark.asyncio
async def test_chat_stream(mock_model_client):
    response = await chat(
        messages=[],
        stream=True,
        client=mock_model_client,
    )
    chunk = None
    async for _chunk in response:
        # Only one chunk.
        chunk = _chunk
    assert chunk and chunk.content == "hello"

# File: .//tests/agents/test_mcp_agent.py
import sys

import pytest

from coagent.agents.mcp_agent import MCPAgent, Prompt
from coagent.core.exceptions import BaseError


class TestMCPAgent:
    @pytest.mark.skipif(sys.platform == "win32", reason="Does not run on Windows.")
    @pytest.mark.asyncio
    async def test_get_prompt(self):
        agent = MCPAgent(mcp_server_base_url="python tests/agents/mcp_server.py")
        await agent.started()

        # Success
        config = Prompt(name="system_prompt", arguments={"role": "Weather Reporter"})
        prompt = await agent._get_prompt(config)
        assert prompt == "You are a helpful Weather Reporter."

        # Error
        config = Prompt(name="x", arguments={"role": "Weather Reporter"})
        with pytest.raises(BaseError) as exc:
            _ = await agent._get_prompt(config)
        assert str(exc.value).startswith("Unknown prompt: x")

        await agent.stopped()

    @pytest.mark.skipif(sys.platform == "win32", reason="Does not run on Windows.")
    @pytest.mark.asyncio
    async def test_get_tools(self):
        agent = MCPAgent(mcp_server_base_url="python tests/agents/mcp_server.py")
        await agent.started()

        tools = await agent._get_tools()
        tool = tools[0]

        assert tool.__name__ == "query_weather"
        assert tool.__doc__ == "Query the weather in the given city."
        assert tool.__mcp_tool_schema__ == {
            "description": "Query the weather in the given city.",
            "name": "query_weather",
            "parameters": {
                "properties": {
                    "city": {
                        "title": "City",
                        "type": "string",
                    }
                },
                "required": ["city"],
                "title": "query_weatherArguments",
                "type": "object",
            },
        }
        assert tool.__mcp_tool_args__ == ("city",)

        result = await tool(city="Beijing")
        assert result == "The weather in Beijing is sunny."

        await agent.stopped()

# File: .//tests/agents/test_structured_agent.py
from typing import AsyncIterator

from coagent.agents import ChatHistory, ChatMessage
from coagent.agents.structured_agent import StructuredAgent
from coagent.core import Context, GenericMessage, Message
from pydantic import BaseModel
import pytest


class Input(Message):
    role: str = ""
    content: str = ""


class Output(BaseModel):
    content: str = ""


class MockAgent(StructuredAgent):
    async def _handle_history(
        self,
        msg: ChatHistory,
        response_format: dict | None = None,
    ) -> AsyncIterator[ChatMessage]:
        if response_format and response_format["json_schema"]["name"] == "Output":
            out = Output(content="Hello!")
            yield ChatMessage(role="assistant", content=out.model_dump_json())
        else:
            yield ChatMessage(role="assistant", content="Hello!")


class TestStructuredAgent:
    @pytest.mark.asyncio
    async def test_render_system(self):
        agent = StructuredAgent(
            input_type=Input, system="You are a helpful {{ role }}."
        )

        system = await agent.render_system(Input(role="Translator"))
        assert system == "You are a helpful Translator."

    @pytest.mark.asyncio
    async def test_render_messages(self):
        agent = StructuredAgent(
            input_type=Input,
            messages=[ChatMessage(role="user", content="{{ content }}")],
        )

        messages = await agent.render_messages(Input(content="Hello"))
        assert messages == [ChatMessage(role="user", content="Hello")]

    @pytest.mark.asyncio
    async def test_handle_input(self):
        agent = MockAgent(
            input_type=Input,
        )

        # Success
        _input = GenericMessage.decode(Input().encode())
        async for msg in agent.handle(_input, Context()):
            assert msg.content == "Hello!"

        # Error
        _input = GenericMessage.decode(ChatMessage(role="").encode())
        with pytest.raises(ValueError) as exc:
            async for _ in agent.handle(_input, Context()):
                pass
        assert "Invalid message type" in str(exc.value)

    @pytest.mark.asyncio
    async def test_handle_output(self):
        agent = MockAgent(
            input_type=Input,
            output_type=Output,
        )

        _input = GenericMessage.decode(Input().encode())
        async for msg in agent.handle(_input, Context()):
            assert msg.content == '{"content":"Hello!"}'

# File: .//tests/agents/mcp_server.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Weather")


@mcp.prompt()
def system_prompt(role: str) -> str:
    """Create a system prompt."""
    return f"You are a helpful {role}."


@mcp.tool()
def query_weather(city: str) -> str:
    """Query the weather in the given city."""
    return f"The weather in {city} is sunny."


if __name__ == "__main__":
    mcp.run()

# File: .//tests/agents/test_messages.py
from pydantic import BaseModel, ValidationError
import pytest

from coagent.agents import ChatHistory, ChatMessage, StructuredOutput


class FriendInfo(BaseModel):
    name: str
    age: int
    is_available: bool


want_output_schema = {
    "json_schema": {
        "name": "FriendInfo",
        "schema": {
            "additionalProperties": False,
            "properties": {
                "age": {
                    "title": "Age",
                    "type": "integer",
                },
                "is_available": {
                    "title": "Is Available",
                    "type": "boolean",
                },
                "name": {
                    "title": "Name",
                    "type": "string",
                },
            },
            "required": [
                "name",
                "age",
                "is_available",
            ],
            "title": "FriendInfo",
            "type": "object",
        },
        "strict": True,
    },
    "type": "json_schema",
}


class TestStructuredOutput:
    @pytest.mark.asyncio
    async def test_chat_message(self):
        # Test model_dump
        output = StructuredOutput(
            input=ChatMessage(role="user", content="I have a friend."),
            output_type=FriendInfo,
        )
        want_output_dict = {
            "input": {
                "__message_type__": "ChatMessage",
                "content": "I have a friend.",
                "role": "user",
            },
            "output_schema": want_output_schema,
            "output_type": None,
        }
        assert output.model_dump(exclude_defaults=True) == want_output_dict

        # Test model_validate
        output2 = StructuredOutput.model_validate(want_output_dict)
        assert isinstance(output2.input, ChatMessage)
        assert output2.input.role == "user"
        assert output2.input.content == "I have a friend."

    @pytest.mark.asyncio
    async def test_chat_history(self):
        # Test model_dump
        output = StructuredOutput(
            input=ChatHistory(
                messages=[ChatMessage(role="user", content="I have a friend.")]
            ),
            output_type=FriendInfo,
        )
        want_output_dict = {
            "input": {
                "__message_type__": "ChatHistory",
                "messages": [
                    {
                        "content": "I have a friend.",
                        "role": "user",
                    }
                ],
            },
            "output_schema": want_output_schema,
            "output_type": None,
        }
        assert output.model_dump(exclude_defaults=True) == want_output_dict

        # Test model_validate
        output2 = StructuredOutput.model_validate(want_output_dict)
        assert isinstance(output2.input, ChatHistory)
        assert output2.input.messages[0].role == "user"
        assert output2.input.messages[0].content == "I have a friend."

    @pytest.mark.asyncio
    async def test_invalid_input(self):
        class InvalidInput(BaseModel):
            pass

        with pytest.raises(ValidationError) as exc:
            _ = StructuredOutput(
                input=InvalidInput(),
                output_type=FriendInfo,
            )

        exc_value = str(exc.value)
        assert "2 validation errors for StructuredOutput" in exc_value
        assert (
            "Input should be a valid dictionary or instance of ChatMessage" in exc_value
        )
        assert (
            "Input should be a valid dictionary or instance of ChatHistory" in exc_value
        )

# File: .//examples/patterns/triaging.py
import asyncio
import os

from coagent.agents import ChatAgent, ChatMessage, DynamicTriage, ModelClient
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime

client = ModelClient(
    model=os.getenv("MODEL_NAME"),
    api_base=os.getenv("MODEL_API_BASE"),
    api_version=os.getenv("MODEL_API_VERSION"),
    api_key=os.getenv("MODEL_API_KEY"),
)

billing = AgentSpec(
    "team.billing",  # Under the team namespace
    new(
        ChatAgent,
        system="""\
You are a billing support specialist. Follow these guidelines:
1. Always start with "Billing Support Response:"
2. First acknowledge the specific billing issue
3. Explain any charges or discrepancies clearly
4. List concrete next steps with timeline
5. End with payment options if relevant

Keep responses professional but friendly.\
""",
        client=client,
    ),
)

account = AgentSpec(
    "team.account",  # Under the team namespace
    new(
        ChatAgent,
        system="""\
You are an account security specialist. Follow these guidelines:
1. Always start with "Account Support Response:"
2. Prioritize account security and verification
3. Provide clear steps for account recovery/changes
4. Include security tips and warnings
5. Set clear expectations for resolution time

Maintain a serious, security-focused tone.\
""",
        client=client,
    ),
)

triage = AgentSpec(
    "triage",
    new(
        DynamicTriage,
        system="""You are a triage agent who will delegate to sub-agents based on the conversation content.""",
        client=client,
        namespace="team",  # Collect all sub-agents under the team namespace
    ),
)


async def main():
    async with LocalRuntime() as runtime:
        for spec in [billing, account, triage]:
            await runtime.register(spec)

        result = await triage.run(
            ChatMessage(
                role="user",
                content="""\
Subject: Can't access my account
Message: Hi, I've been trying to log in for the past hour but keep getting an 'invalid password' error. 
I'm sure I'm using the right password. Can you help me regain access? This is urgent as I need to 
submit a report by end of day.
- John\
""",
            ).encode(),
            stream=True,
        )
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/patterns/chaining.py
import asyncio
import os

from coagent.agents import ChatAgent, Sequential, ModelClient
from coagent.agents.messages import ChatMessage
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime

client = ModelClient(
    model=os.getenv("MODEL_NAME"),
    api_base=os.getenv("MODEL_API_BASE"),
    api_version=os.getenv("MODEL_API_VERSION"),
    api_key=os.getenv("MODEL_API_KEY"),
)

extractor = AgentSpec(
    "extractor",
    new(
        ChatAgent,
        system="""\
Extract only the numerical values and their associated metrics from the text.
Format each as 'value: metric' on a new line.
Example format:
92: customer satisfaction
45%: revenue growth\
""",
        client=client,
    ),
)

converter = AgentSpec(
    "converter",
    new(
        ChatAgent,
        system="""\
Convert all numerical values to percentages where possible.
If not a percentage or points, convert to decimal (e.g., 92 points -> 92%).
Keep one number per line.
Example format:
92%: customer satisfaction
45%: revenue growth\
""",
        client=client,
    ),
)

sorter = AgentSpec(
    "sorter",
    new(
        ChatAgent,
        system="""\
Sort all lines in descending order by numerical value.
Keep the format 'value: metric' on each line.
Example:
92%: customer satisfaction
87%: employee satisfaction\
""",
        client=client,
    ),
)

formatter = AgentSpec(
    "formatter",
    new(
        ChatAgent,
        system="""\
Format the sorted data as a markdown table with columns:
| Metric | Value |
|:--|--:|
| Customer Satisfaction | 92% |\
""",
        client=client,
    ),
)

chain = AgentSpec(
    "chain", new(Sequential, "extractor", "converter", "sorter", "formatter")
)


async def main():
    async with LocalRuntime() as runtime:
        for spec in [extractor, converter, sorter, formatter, chain]:
            await runtime.register(spec)

        result = await chain.run(
            ChatMessage(
                role="user",
                content="""\
Q3 Performance Summary:
Our customer satisfaction score rose to 92 points this quarter.
Revenue grew by 45% compared to last year.
Market share is now at 23% in our primary market.
Customer churn decreased to 5% from 8%.
New user acquisition cost is $43 per user.
Product adoption rate increased to 78%.
Employee satisfaction is at 87 points.
Operating margin improved to 34%.\
""",
            ).encode(),
            stream=True,
        )
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/patterns/parallelization.py
import asyncio
import os

from coagent.agents import (
    Aggregator,
    AggregationResult,
    ChatAgent,
    ChatMessage,
    ModelClient,
    Parallel,
)
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime

client = ModelClient(
    model=os.getenv("MODEL_NAME"),
    api_base=os.getenv("MODEL_API_BASE"),
    api_version=os.getenv("MODEL_API_VERSION"),
    api_key=os.getenv("MODEL_API_KEY"),
)

customer = AgentSpec(
    "customer",
    new(
        ChatAgent,
        system="""\
Customers:
- Price sensitive
- Want better tech
- Environmental concerns\
""",
        client=client,
    ),
)

employee = AgentSpec(
    "employee",
    new(
        ChatAgent,
        system="""\
Employees:
- Job security worries
- Need new skills
- Want clear direction\
""",
        client=client,
    ),
)

investor = AgentSpec(
    "investor",
    new(
        ChatAgent,
        system="""\
Investors:
- Expect growth
- Want cost control
- Risk concerns\
""",
        client=client,
    ),
)

supplier = AgentSpec(
    "supplier",
    new(
        ChatAgent,
        system="""\
Suppliers:
- Capacity constraints
- Price pressures
- Tech transitions\
""",
        client=client,
    ),
)

aggregator = AgentSpec("aggregator", new(Aggregator))

parallel = AgentSpec(
    "parallel",
    new(
        Parallel,
        "customer",
        "employee",
        "investor",
        "supplier",
        aggregator="aggregator",
    ),
)


async def main():
    async with LocalRuntime() as runtime:
        for spec in [customer, employee, investor, supplier, aggregator, parallel]:
            await runtime.register(spec)

        result = await parallel.run(
            ChatMessage(
                role="user",
                content="""\
Analyze how market changes will impact this stakeholder group.
Provide specific impacts and recommended actions.
Format with clear sections and priorities.\
""",
            ).encode()
        )
        msg = AggregationResult.decode(result)
        for result in msg.results:
            x = ChatMessage.decode(result)
            print(x.content)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/patterns/augmented_llm.py
import asyncio
import os

from coagent.agents import ChatAgent, ModelClient, tool
from coagent.agents.messages import ChatMessage
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime


class Assistant(ChatAgent):
    system = """You are an agent who can use tools."""
    client = ModelClient(
        model=os.getenv("MODEL_NAME"),
        api_base=os.getenv("MODEL_API_BASE"),
        api_version=os.getenv("MODEL_API_VERSION"),
        api_key=os.getenv("MODEL_API_KEY"),
    )

    @tool
    async def query_weather(self, city: str) -> str:
        """Query the weather in the given city."""
        return f"The weather in {city} is sunny."


assistant = AgentSpec("assistant", new(Assistant))


async def main():
    async with LocalRuntime() as runtime:
        await runtime.register(assistant)

        result = await assistant.run(
            ChatMessage(
                role="user",
                content="What's the weather like in Beijing?",
            ).encode(),
            stream=True,
        )
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger("TRACE")
    asyncio.run(main())

# File: .//examples/notification/notification.py
import asyncio
from typing import AsyncIterator

from coagent.core import (
    Address,
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    idle_loop,
    logger,
    Message,
    new,
    set_stderr_logger,
)
from coagent.core.messages import ControlMessage
from coagent.runtimes import NATSRuntime


class Notification(Message):
    type: str
    content: str


class Subscribe(Message):
    user_id: str


class Notify(Message):
    user_id: str
    notification: Notification


class _SubscribeToCenter(Message):
    user_id: str
    sender: Address


class _UnsubscribeFromCenter(Message):
    user_id: str


class _ControlNotify(ControlMessage):
    """A CONTROL message for putting a notification into the queue."""

    notification: Notification


class Proxy(BaseAgent):
    """A proxy agent that accepts subscriptions from the user and forwards the
    notifications from the singleton center agent to the user.
    """

    def __init__(self):
        # The agent is long-running and will be deleted when the user cancels.
        super().__init__(timeout=float("inf"))

        self.__queue: asyncio.Queue[Notification] = asyncio.Queue()

    @handler
    async def notify(self, msg: _ControlNotify, ctx: Context) -> None:
        await self.__queue.put(msg.notification)

    @handler
    async def subscribe(
        self, msg: Subscribe, ctx: Context
    ) -> AsyncIterator[Notification]:
        # Subscribe to the singleton center agent.
        await self.channel.publish(
            Center.SINGLETON_ADDRESS,
            _SubscribeToCenter(user_id=msg.user_id, sender=self.address).encode(),
        )

        while True:
            try:
                # Forward notifications from the center agent to the user.
                notification = await self.__queue.get()
                self.__queue.task_done()
                yield notification
            except asyncio.CancelledError:
                # Unsubscribe from the center agent when the user cancelled.
                await self.channel.publish(
                    Center.SINGLETON_ADDRESS,
                    _UnsubscribeFromCenter(user_id=msg.user_id).encode(),
                )
                raise


class Center(BaseAgent):
    """A center agent that listens to notifications and forwards them to the
    appropriate subscribing agents.
    """

    SINGLETON_ADDRESS = Address(name="center", id="singleton")

    def __init__(self):
        # This is a long-running agent and has the same lifetime as the application.
        super().__init__(timeout=float("inf"))

        self.__subscribers: dict[str, Address] = {}

    @handler
    async def subscribe(self, msg: _SubscribeToCenter, ctx: Context) -> None:
        self.__subscribers[msg.user_id] = msg.sender
        logger.info(f"User {msg.user_id} subscribed")

    @handler
    async def unsubscribe(self, msg: _UnsubscribeFromCenter, ctx: Context) -> None:
        self.__subscribers.pop(msg.user_id, None)
        logger.info(f"User {msg.user_id} unsubscribed")

    @handler
    async def notify(self, msg: Notify, ctx: Context) -> None:
        addr = self.__subscribers.get(msg.user_id)
        if not addr:
            logger.warning(f"User {msg.user_id} is not subscribed")
            return

        _notify = _ControlNotify(notification=msg.notification)
        await self.channel.publish(addr, _notify.encode())
        logger.info(f"Notification sent to user {msg.user_id}")


proxy = AgentSpec("proxy", new(Proxy))
center = AgentSpec("center", new(Center))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(proxy)
        await runtime.register(center)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/client.py
import asyncio
import argparse
import uuid

from coagent.agents.chat_agent import ChatHistory, ChatMessage
from coagent.core import Address, set_stderr_logger
from coagent.core.util import exit_loop
from coagent.runtimes import NATSRuntime


async def main(agent_name: str):
    session_id = uuid.uuid4().hex
    addr = Address(name=agent_name, id=session_id)
    history: ChatHistory = ChatHistory(messages=[])

    async with NATSRuntime.from_servers() as runtime:
        while True:
            try:
                query = await asyncio.to_thread(input, "User> ")
            except EOFError:
                exit_loop()
                return

            if query == "exit":
                exit_loop()
                return

            msg = ChatMessage(role="user", content=query)
            history.messages.append(msg)
            result = await runtime.send(addr, history, request=True, timeout=50)
            content = result.messages[-1].content
            history.messages.append(ChatMessage(role="assistant", content=content))
            print(f"Assistant> {content}")


if __name__ == "__main__":
    set_stderr_logger("ERROR")

    parser = argparse.ArgumentParser()
    parser.add_argument("agent", type=str)
    args = parser.parse_args()

    asyncio.run(main(args.agent))

# File: .//examples/discovery/server.py
import argparse
import asyncio

from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    GenericMessage,
    handler,
    idle_loop,
    new,
    set_stderr_logger,
)
from coagent.runtimes import NATSRuntime, HTTPRuntime


class Employee(BaseAgent):
    @handler
    async def handle(self, msg: GenericMessage, ctx: Context) -> GenericMessage:
        return msg


async def main(name: str, description: str, server: str):
    if server.startswith("nats://"):
        runtime = NATSRuntime.from_servers(server)
    elif server.startswith(("http://", "https://")):
        runtime = HTTPRuntime.from_server(server)
    else:
        raise ValueError(f"Unsupported server: {server}")

    employee = AgentSpec(name, new(Employee), description=description)

    async with runtime:
        await runtime.register(employee)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("name", type=str)
    parser.add_argument("description", type=str)
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    args = parser.parse_args()

    asyncio.run(main(args.name, args.description, args.server))

# File: .//examples/discovery/client.py
import argparse
import asyncio
import json

from coagent.core import (
    Address,
    DiscoveryQuery,
    DiscoveryReply,
    RawMessage,
    set_stderr_logger,
)
from coagent.runtimes import NATSRuntime, HTTPRuntime


async def main(
    server: str, namespace: str, recursive: bool, inclusive: bool, schema: bool
):
    if server.startswith("nats://"):
        runtime = NATSRuntime.from_servers(server)
    elif server.startswith(("http://", "https://")):
        runtime = HTTPRuntime.from_server(server)
    else:
        raise ValueError(f"Unsupported server: {server}")

    async with runtime:
        result: RawMessage = await runtime.channel.publish(
            Address(name="discovery"),
            DiscoveryQuery(
                namespace=namespace,
                recursive=recursive,
                inclusive=inclusive,
            ).encode(),
            request=True,
            probe=False,
        )
        reply: DiscoveryReply = DiscoveryReply.decode(result)

        for agent in reply.agents:
            ops_str = ""
            if schema:
                ops = [op.model_dump() for op in agent.operations]
                ops_str = " " + json.dumps(ops, indent=2)
            print(
                f"\033[1m\033[95m{agent.name}:\033[00m \033[1m\033[92m{agent.description}\033[00m{ops_str}"
            )


if __name__ == "__main__":
    set_stderr_logger("ERROR")

    parser = argparse.ArgumentParser()
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    parser.add_argument("--namespace", type=str, default="")
    parser.add_argument("--recursive", action="store_true")
    parser.add_argument("--inclusive", action="store_true")
    parser.add_argument("--schema", action="store_true")
    args = parser.parse_args()

    asyncio.run(
        main(args.server, args.namespace, args.recursive, args.inclusive, args.schema)
    )

# File: .//examples/mcp/server.py
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Weather", port=8080)


@mcp.prompt()
def system_prompt(role: str) -> str:
    """Create a system prompt."""
    return f"You are a helpful {role}."


@mcp.tool()
def query_weather(city: str) -> str:
    """Query the weather in the given city."""
    return f"The weather in {city} is sunny."


if __name__ == "__main__":
    mcp.run(transport="sse")

# File: .//examples/mcp/agent.py
import asyncio

from coagent.agents import MCPAgent
from coagent.agents.mcp_agent import Prompt
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime


mcp = AgentSpec(
    "mcp",
    new(
        MCPAgent,
        system=Prompt(name="system_prompt", arguments={"role": "Weather Reporter"}),
        mcp_server_base_url="http://localhost:8080",
    ),
)


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(mcp)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")
    asyncio.run(main())

# File: .//examples/translator/translator.py
# translator.py
# Monolithic Approach
import asyncio
import os

from coagent.agents import ChatAgent, ChatMessage, ModelClient
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime

translator = AgentSpec(
    "translator",
    new(
        ChatAgent,
        system="You are a professional translator that can translate Chinese to English.",
        client=ModelClient(model="openai/gpt-4o", api_key=os.getenv("OPENAI_API_KEY")),
    ),
)


async def main():
    async with LocalRuntime() as runtime:
        await runtime.register(translator)

        result = await translator.run(
            ChatMessage(role="user", content="你好，世界").encode(),
            stream=True,
        )
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())
# File: .//examples/cos/cos.py
import abc
import argparse
import asyncio
import json
from urllib.parse import urljoin
import signal
from typing import Any, Type

import httpx
from httpx_sse import aconnect_sse


class Channel:
    def __init__(self, base_url: str, auth: str = ""):
        self._base_url = base_url
        self._headers = {"Authorization": f"Bearer {auth}"} if auth else None

    async def publish(self, addr: dict, msg: dict) -> dict | None:
        data = dict(
            addr=addr,
            msg=msg,
        )
        async with httpx.AsyncClient() as client:
            url = urljoin(self._base_url, "/runtime/channel/publish")
            resp = await client.post(url, json=data, headers=self._headers)
            resp.raise_for_status()

            # TODO: Handle result.

    async def publish_multi(self, addr: dict, handler) -> None:
        pass

    async def subscribe(self, path: str, data: dict, handler):
        async with httpx.AsyncClient(timeout=None) as client:
            async with aconnect_sse(
                client,
                "POST",
                urljoin(self._base_url, path),
                json=data,
                headers=self._headers or {},
            ) as event_source:
                async for sse in event_source.aiter_sse():
                    data_str = sse.data
                    data = json.loads(data_str)
                    await handler(data)

    async def request(self, path: str, data: dict) -> dict | None:
        pass


class Runtime:
    def __init__(self, base_url: str, auth: str = ""):
        self._channel = Channel(base_url, auth)
        self._factories: dict[str, Type] = {}

    async def register(self, name: str, constructor: Type, description: str = ""):
        if name in self._factories:
            raise ValueError(f"Agent {name} already registered")
        self._factories[name] = constructor

        data = dict(
            name=name,
            description=description,
        )
        coro = self._channel.subscribe("/runtime/register", data, self.handle)
        _ = asyncio.create_task(coro)

    async def handle(self, data: dict):
        match data["header"]["type"]:
            case "AgentCreated":
                await self.create_agent(data)
            case "AgentDeleted":
                await self.delete_agent(data)

    async def create_agent(self, data: dict):
        addr = json.loads(data["content"])["addr"]
        constructor = self._factories[addr["name"]]

        print(f"Creating agent with addr: {addr}")
        agent = constructor(self._channel, addr)
        coro = self._channel.subscribe(
            "runtime/channel/subscribe", dict(addr=addr), agent.receive
        )
        _ = asyncio.create_task(coro)

    async def delete_agent(self, data: dict):
        pass


async def idle_loop():
    try:
        stop_event = asyncio.Event()

        loop = asyncio.get_event_loop()
        loop.add_signal_handler(signal.SIGINT, stop_event.set)

        while not stop_event.is_set():
            await asyncio.sleep(1)

    except asyncio.CancelledError:
        pass


class Agent(abc.ABC):
    def __init__(self, channel: Channel, addr: dict):
        self.channel = channel
        self.addr = addr

    async def receive(self, msg: dict) -> None:
        print(f"Received a message: {msg}")

        result = self.handle(msg)

        reply = msg.get("reply") or {}
        reply_addr = reply.get("address")
        if not reply_addr:
            return

        if is_async_iterator(result):
            async for x in result:
                await self.channel.publish(reply_addr, x)
            # End of the iteration, send an extra StopIteration message.
            stop = {"header": {"type": "StopIteration"}}
            await self.channel.publish(reply_addr, stop)
        else:
            x = await result
            await self.channel.publish(reply_addr, x)

    @abc.abstractmethod
    async def handle(self, msg: dict) -> Any:
        pass


def is_async_iterator(obj) -> bool:
    """Check if obj is an async-iterator."""
    return hasattr(obj, "__aiter__") and hasattr(obj, "__anext__")


class Server(Agent):
    async def handle(self, msg: dict) -> Any:
        return {"header": {"type": "Pong"}}


class StreamServer(Agent):
    async def handle(self, msg: dict) -> Any:
        words = ("Hi ", "there, ", "this ", "is ", "the ", "Pong ", "server.")
        for word in words:
            await asyncio.sleep(0.6)
            yield {
                "header": {"type": "PartialPong"},
                "content": json.dumps({"content": word}),
            }


async def main(base_url: str, auth: str):
    runtime = Runtime(base_url, auth)
    await runtime.register("server", Server)
    await runtime.register("stream_server", StreamServer)
    await idle_loop()


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--server", type=str, default="http://127.0.0.1:8000")
    parser.add_argument("--auth", type=str, default="")
    args = parser.parse_args()

    asyncio.run(main(args.server, args.auth))

# File: .//examples/stream-ping-pong/server.py
import argparse
import asyncio
from typing import AsyncIterator

from pydantic import Field

from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    idle_loop,
    Message,
    new,
    set_stderr_logger,
)
from coagent.runtimes import NATSRuntime, HTTPRuntime


class Ping(Message):
    pass


class PartialPong(Message):
    content: str = Field(..., description="The content of the Pong message.")


class StreamServer(BaseAgent):
    """The Stream Pong Server."""

    @handler
    async def handle(self, msg: Ping, ctx: Context) -> AsyncIterator[PartialPong]:
        """Handle the Ping message and return a stream of PartialPong messages."""
        words = ("Hi ", "there, ", "this ", "is ", "the ", "Pong ", "server.")
        for word in words:
            await asyncio.sleep(0.6)
            yield PartialPong(content=word)


stream_server = AgentSpec("stream_server", new(StreamServer))


async def main(server: str, auth: str):
    if server.startswith("nats://"):
        runtime = NATSRuntime.from_servers(server)
    elif server.startswith(("http://", "https://")):
        runtime = HTTPRuntime.from_server(server, auth)
    else:
        raise ValueError(f"Unsupported server: {server}")

    async with runtime:
        await runtime.register(stream_server)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    parser.add_argument("--auth", type=str, default="")
    args = parser.parse_args()

    asyncio.run(main(args.server, args.auth))

# File: .//examples/deepseek-r1/agent.py
import asyncio
import os

from coagent.agents import ChatAgent, ChatMessage, ModelClient
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime


client = ModelClient(
    model="openai/deepseek-reasoner",
    api_base="https://api.deepseek.com/v1",
    api_key=os.getenv("DEEPSEEK_API_KEY"),
)


deepseek_reasoner = AgentSpec("deepseek_reasoner", new(ChatAgent, client=client))


async def main():
    async with LocalRuntime() as runtime:
        await runtime.register(deepseek_reasoner)

        result = await deepseek_reasoner.run(
            ChatMessage(
                role="user", content="9.11 and 9.8, which is greater?"
            ).encode(),
            stream=True,
        )

        reasoning_started = False
        reasoning_stopped = False
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            if msg.reasoning_content:
                if not reasoning_started:
                    print("<think>", flush=True)
                    reasoning_started = True
                print(msg.reasoning_content, end="", flush=True)
            if msg.content:
                if reasoning_started and not reasoning_stopped:
                    print("</think>", flush=True)
                    reasoning_stopped = True
                print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/rich_client.py
"""Most of the Textual code is borrowed from https://gist.github.com/willmcgugan/648a537c9d47dafa59cb8ece281d8c2c."""

import argparse
import json
from typing import List, Union, AsyncIterator
import uuid

from coagent.agents.chat_agent import ChatHistory, ChatMessage
from coagent.core import Address, set_stderr_logger
from coagent.runtimes import NATSRuntime, HTTPRuntime

from textual import on, work  # noqa: F401
from textual.app import App, ComposeResult
from textual.widgets import Header, Input, Footer, Markdown, Button
from textual.containers import Horizontal, VerticalScroll  # noqa: F401


class Bot:
    runtime: NATSRuntime | None = None
    history: ChatHistory = ChatHistory(messages=[])
    addr: Address | None = None
    server: Union[str, List[str], None] = None
    auth: str = ""
    ext: dict | None = None

    @classmethod
    async def ainit(cls):
        if cls.server.startswith("nats://"):
            runtime = NATSRuntime.from_servers(cls.server)
        elif cls.server.startswith(("http://", "https://")):
            runtime = HTTPRuntime.from_server(cls.server, cls.auth)
        else:
            raise ValueError(f"Unsupported server: {cls.server}")
        cls.runtime = runtime
        await cls.runtime.start()

        cls.history.extensions = cls.ext or {}

    @classmethod
    async def asend(cls, query: str) -> AsyncIterator[ChatMessage]:
        msg = ChatMessage(role="user", content=query)
        cls.history.messages.append(msg)
        result = await cls.runtime.channel.publish(
            cls.addr,
            cls.history.encode(),
            stream=True,
        )
        full_reply = ChatMessage(role="assistant", content="")
        async for chunk in result:
            reply = ChatMessage.decode(chunk)

            full_reply.to_user = reply.to_user
            full_reply.type = reply.type
            full_reply.content += reply.content

            yield reply
        cls.history.messages.append(full_reply)

    @classmethod
    async def clear(cls):
        cls.history.messages.clear()


class Prompt(Markdown):
    pass


class Response(Markdown):
    BORDER_TITLE = "Assistant"


class BotApp(App):
    AUTO_FOCUS = "Input"

    CSS = """
    Prompt {
        background: $primary 10%;
        color: $text;
        margin: 1;
        margin-right: 8;
        padding: 1 2 0 2;
    }

    Response {
        border: wide $success;
        background: $success 10%;
        color: $text;
        margin: 1;
        margin-left: 8;
        padding: 1 2 0 2;
    }
    """

    def compose(self) -> ComposeResult:
        yield Header()
        with VerticalScroll(id="chat-view"):
            yield Response("Good day! How can I assist you?")
        yield Input(placeholder="Input")
        # with Horizontal():
        #     yield Input(placeholder="Input")
        #     yield Button("Clear", id="clear-button")
        yield Footer()

    async def on_mount(self) -> None:
        await Bot.ainit()

    @on(Button.Pressed, "#clear-button")
    async def on_clear(self, event: Button.Pressed) -> None:
        await Bot.clear()

    @on(Input.Submitted)
    async def on_input(self, event: Input.Submitted) -> None:
        chat_view = self.query_one("#chat-view")
        event.input.clear()
        await chat_view.mount(Prompt(event.value))
        chat_view.scroll_end()

        await chat_view.mount(response := Response())
        await self.send_prompt(event.value, response)
        chat_view.scroll_end()

    async def send_prompt(self, prompt: str, response: Response) -> None:
        bot_response = Bot.asend(prompt)
        full_content = ""
        async for chunk in bot_response:
            if not full_content and chunk.sender:
                full_content = f"[{chunk.sender}] "
            full_content += chunk.content
            await response.update(full_content)


if __name__ == "__main__":
    set_stderr_logger("ERROR")

    parser = argparse.ArgumentParser()
    parser.add_argument("agent", type=str)
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    parser.add_argument("--auth", type=str, default="")
    parser.add_argument("--ext", type=str, default="{}")
    args = parser.parse_args()

    session_id = uuid.uuid4().hex
    Bot.addr = Address(name=args.agent, id=session_id)
    Bot.server = args.server
    Bot.auth = args.auth
    Bot.ext = json.loads(args.ext)

    app = BotApp()
    app.run()

# File: .//examples/rich_client_textarea.py
"""Most of the Textual code is borrowed from https://gist.github.com/willmcgugan/648a537c9d47dafa59cb8ece281d8c2c."""

import argparse
import uuid

from coagent.agents.chat_agent import ChatHistory, ChatMessage
from coagent.core import Address, set_stderr_logger
from coagent.runtimes import NATSRuntime, HTTPRuntime

from textual import on, work  # noqa: F401
from textual.app import App, ComposeResult
from textual.widgets import Header, Input, Footer, Markdown, Button, TextArea
from textual.containers import Horizontal, VerticalScroll  # noqa: F401
from typing import List, Union, AsyncIterator
from textual import events  # noqa: F401


class Bot:
    runtime: NATSRuntime | None = None
    history: ChatHistory = ChatHistory(messages=[])
    addr: Address | None = None
    server: Union[str, List[str], None] = None
    auth: str = ""

    @classmethod
    async def ainit(cls):
        if cls.server.startswith("nats://"):
            runtime = NATSRuntime.from_servers(cls.server)
        elif cls.server.startswith(("http://", "https://")):
            runtime = HTTPRuntime.from_server(cls.server, cls.auth)
        else:
            raise ValueError(f"Unsupported server: {cls.server}")
        cls.runtime = runtime
        await cls.runtime.start()

    @classmethod
    async def asend(cls, query: str) -> AsyncIterator[str]:
        msg = ChatMessage(role="user", content=query)
        cls.history.messages.append(msg)
        result = await cls.runtime.channel.publish(
            cls.addr,
            cls.history.encode(),
            stream=True,
        )
        content = ""
        async for chunk in result:
            reply = ChatMessage.decode(chunk)
            content += reply.content
            yield reply.content
        cls.history.messages.append(ChatMessage(role="assistant", content=content))

    @classmethod
    async def clear(cls):
        cls.data.messages.clear()


class Prompt(Markdown):
    pass


class Response(Markdown):
    BORDER_TITLE = "Assistant"


class BotApp(App):
    AUTO_FOCUS = "Input"

    CSS = """
    Prompt {
        background: $primary 10%;
        color: $text;
        margin: 1;
        margin-right: 8;
        padding: 1 2 0 2;
    }

    Response {
        border: wide $success;
        background: $success 10%;
        color: $text;
        margin: 1;
        margin-left: 8;
        padding: 1 2 0 2;
    }
    """

    def compose(self) -> ComposeResult:
        yield Header()
        with VerticalScroll(id="chat-view"):
            yield Response("Good day! How can I assist you?")
        # yield Input(placeholder="Input")
        self.textArea = TextArea(text="")
        yield self.textArea
        # with Horizontal():
        #     yield Input(placeholder="Input")
        #     yield Button("Clear", id="clear-button")
        yield Button("Send", id="send-button")
        yield Footer()

    async def on_mount(self) -> None:
        await Bot.ainit()

    @on(Button.Pressed, "#clear-button")
    async def on_clear(self, event: Button.Pressed) -> None:
        await Bot.clear()

    @on(Button.Pressed, "#send-button")
    async def on_send(self, event: Button.Pressed) -> None:
        chat_view = self.query_one("#chat-view")
        sendValue = self.textArea.text
        self.textArea.text = ""
        await chat_view.mount(Prompt(sendValue))
        chat_view.scroll_end()

        await chat_view.mount(response := Response())
        await self.send_prompt(sendValue, response)
        chat_view.scroll_end()

    @on(Input.Submitted)
    async def on_input(self, event: Input.Submitted) -> None:
        chat_view = self.query_one("#chat-view")
        event.input.clear()
        await chat_view.mount(Prompt(event.value))
        chat_view.scroll_end()

        await chat_view.mount(response := Response())
        await self.send_prompt(event.value, response)
        chat_view.scroll_end()

    async def send_prompt(self, prompt: str, response: Response) -> None:
        bot_response = Bot.asend(prompt)
        full_content = ""
        async for content in bot_response:
            full_content += content
            await response.update(full_content)


if __name__ == "__main__":
    set_stderr_logger("ERROR")

    parser = argparse.ArgumentParser()
    parser.add_argument("agent", type=str, default="")
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    parser.add_argument("--auth", type=str, default="")
    args = parser.parse_args()

    session_id = uuid.uuid4().hex
    Bot.addr = Address(name=args.agent, id=session_id)
    Bot.server = args.server
    Bot.auth = args.auth

    app = BotApp()
    app.run()

# File: .//examples/ping-pong/server.py
import argparse
import asyncio

from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    idle_loop,
    Message,
    new,
    set_stderr_logger,
)
from coagent.runtimes import NATSRuntime, HTTPRuntime


class Ping(Message):
    pass


class Pong(Message):
    pass


class Server(BaseAgent):
    """The Pong Server."""

    @handler
    async def handle(self, msg: Ping, ctx: Context) -> Pong:
        """Handle the Ping message and return a Pong message."""
        return Pong()


pong_server = AgentSpec("server", new(Server))


async def main(server: str, auth: str):
    if server.startswith("nats://"):
        runtime = NATSRuntime.from_servers(server)
    elif server.startswith(("http://", "https://")):
        runtime = HTTPRuntime.from_server(server, auth)
    else:
        raise ValueError(f"Unsupported server: {server}")

    async with runtime:
        await runtime.register(pong_server)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("--server", type=str, default="nats://localhost:4222")
    parser.add_argument("--auth", type=str, default="")
    args = parser.parse_args()

    asyncio.run(main(args.server, args.auth))

# File: .//examples/ping-pong/http_runtime_server.py
import os  # noqa: F401
from typing import AsyncIterator

from starlette.applications import Starlette
from starlette.requests import Request
from starlette.responses import Response, JSONResponse
from starlette.routing import Route
from sse_starlette.sse import EventSourceResponse

from coagent.core import Address, RawMessage
from coagent.core.exceptions import BaseError
from coagent.runtimes import HTTPChannelBackend, LocalChannel, NATSChannel  # noqa: F401


# NATS_URL = os.getenv("NATS_URL", "nats://localhost:4222")
# channel = NATSChannel(NATS_URL)
channel = LocalChannel()
backend = HTTPChannelBackend(channel)


async def startup():
    await backend.start()


async def shutdown():
    await backend.stop()


async def publish(request: Request):
    data: dict = await request.json()

    addr: Address = Address.model_validate(data["addr"])
    msg: RawMessage = RawMessage.model_validate(data["msg"])
    stream: bool = data.get("stream", False)
    _request: bool = data.get("request", False)
    reply: str = data.get("reply", "")
    timeout: float = data.get("timeout", 0.5)
    probe: bool = data.get("probe", True)

    # Streaming
    if stream:
        msgs: AsyncIterator[RawMessage] = await backend.publish(
            addr=addr, msg=msg, stream=stream, probe=probe
        )

        async def event_stream() -> AsyncIterator[str]:
            try:
                async for raw in msgs:
                    yield dict(data=raw.encode_json())
            except BaseError as exc:
                yield dict(event="error", data=exc.encode_json())

        return EventSourceResponse(event_stream())

    # Non-streaming
    try:
        resp: RawMessage | None = await backend.publish(
            addr=addr,
            msg=msg,
            stream=stream,
            request=_request,
            reply=reply,
            timeout=timeout,
            probe=probe,
        )
    except BaseError as exc:
        return JSONResponse(exc.encode(mode="json"), status_code=404)

    if resp is None:
        return Response(status_code=204)
    else:
        return JSONResponse(resp.encode(mode="json"))


async def subscribe(request: Request):
    data: dict = await request.json()
    msgs: AsyncIterator[RawMessage] = backend.subscribe(
        addr=Address.model_validate(data["addr"]),
        queue=data["queue"],
    )

    async def event_stream() -> AsyncIterator[str]:
        async for raw in msgs:
            yield dict(data=raw.encode_json())

    return EventSourceResponse(event_stream())


async def new_reply_topic(request: Request):
    topic = await backend.new_reply_topic()
    return JSONResponse(dict(reply_topic=topic))


routes = [
    Route("/publish", publish, methods=["POST"]),
    Route("/subscribe", subscribe, methods=["POST"]),
    Route("/reply-topics", new_reply_topic, methods=["POST"]),
]


app = Starlette(debug=True, routes=routes, on_startup=[startup], on_shutdown=[shutdown])


if __name__ == "__main__":
    import asyncio
    from hypercorn.asyncio import serve
    from hypercorn.config import Config

    config = Config()
    config.bind = ["127.0.0.1:8000"]
    asyncio.run(serve(app, config))

# File: .//examples/structured-outputs/daemon_agent.py
import asyncio

from coagent.agents import ChatAgent, ModelClient
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime
from pydantic import BaseModel


class FriendInfo(BaseModel):
    name: str
    age: int
    is_available: bool


class FriendList(BaseModel):
    friends: list[FriendInfo]


client = ModelClient(
    model="openai/llama3.1",
    api_base="http://localhost:11434/v1",
    api_key="ollama",
)


structured = AgentSpec(
    "structured",
    new(
        ChatAgent,
        client=client,
    ),
)


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(structured)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/structured-outputs/local_agent.py
import asyncio

from coagent.agents import ChatAgent, ChatMessage, ModelClient, StructuredOutput
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.runtimes import LocalRuntime
from pydantic import BaseModel


class FriendInfo(BaseModel):
    name: str
    age: int
    is_available: bool


class FriendList(BaseModel):
    friends: list[FriendInfo]


client = ModelClient(
    model="openai/llama3.1",
    api_base="http://localhost:11434/v1",
    api_key="ollama",
)


structured = AgentSpec(
    "structured",
    new(
        ChatAgent,
        client=client,
    ),
)


async def main():
    async with LocalRuntime() as runtime:
        await runtime.register(structured)

        result = await structured.run(
            StructuredOutput(
                input=ChatMessage(
                    role="user",
                    content="\
I have two friends. The first is Ollama 22 years old busy saving the world, \
and the second is Alonso 23 years old and wants to hang out. Return a list \
of friends in JSON format",
                ),
                output_type=FriendList,
            ).encode(),
            stream=True,
        )
        async for chunk in result:
            msg = ChatMessage.decode(chunk)
            print(msg.content, end="", flush=True)


if __name__ == "__main__":
    set_stderr_logger()
    asyncio.run(main())

# File: .//examples/opencsg/opencsg.py
import argparse
import asyncio

from coagent.agents import DynamicTriage
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime


class OpenCSG(DynamicTriage):
    """OpenCSG Triage Agent."""

    system = "You are a triage agent with a series of tools for different tasks." ""
    namespace = ""


opencsg = AgentSpec("opencsg", new(OpenCSG))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(opencsg)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("--namespace", type=str, default="")
    args = parser.parse_args()

    OpenCSG.namespace = args.namespace
    asyncio.run(main())

# File: .//examples/opencsg/dataflow.py
import argparse
import asyncio

from coagent.agents import ChatAgent, RunContext, submit, tool
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime

import httpx
from pydantic import Field


class DataFlow(ChatAgent):
    """An agent that help users deal with tasks related to datasets."""

    system = "You are an agent that help users deal with tasks related to datasets."

    @tool
    @submit()
    async def search_dataset(
        self, ctx: RunContext, name: str = Field(description="The name of the dataset")
    ) -> str:
        """Search datasets by the given name."""
        async with httpx.AsyncClient() as client:
            resp = await client.get(
                "https://hub.opencsg.com/api/v1/datasets",
                params=dict(search=name),
            )
            if resp.status_code != 200:
                return f"Error: {resp.text}"
            datasets = resp.json()["data"]
            if not datasets:
                return "Sorry, no datasets found."
            return ", ".join([d["name"] for d in datasets])


async def main(name: str):
    dataflow = AgentSpec(name, new(DataFlow))
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(dataflow)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("--name", type=str, default="dataflow")
    args = parser.parse_args()

    asyncio.run(main(args.name))

# File: .//examples/opencsg/csghub.py
import argparse
import asyncio
from enum import Enum

from coagent.agents import ChatAgent, confirm, RunContext, tool
from coagent.agents.messages import ChatMessage
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime

import httpx
from pydantic import Field


class Language(str, Enum):
    unknown = ""
    en = "en"
    zh = "zh"
    ja = "ja"
    de = "de"


class CSGHub(ChatAgent):
    """An agent that help users deal with tasks related to models."""

    system = "You are an assistant that help users deal with tasks related to models."

    @tool
    @confirm("About to search model {name}, are you sure?")
    async def search_model(
        self,
        ctx: RunContext,
        name: str = Field(description="The name of the model"),
        language: Language = Field(description="The language that the model supports"),  # noqa: B008
        limit: int = Field(
            default=10, description="The maximum number of models to return"
        ),
    ) -> str | ChatMessage:
        """Search models by the given name and language."""
        params = dict()
        if name:
            params["search"] = name
        if language:
            params["language"] = language
        if limit:
            params["per"] = limit

        async with httpx.AsyncClient() as client:
            resp = await client.get(
                "https://hub.opencsg.com/api/v1/models",
                params=params,
            )
            if resp.status_code != 200:
                return f"Error: {resp.text}"
            models = resp.json()["data"]
            if not models:
                return "Sorry, no models found."
            return ", ".join([m["name"] for m in models])


async def main(name: str):
    csghub = AgentSpec(name, new(CSGHub))
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(csghub)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    parser = argparse.ArgumentParser()
    parser.add_argument("--name", type=str, default="csghub")
    args = parser.parse_args()

    asyncio.run(main(args.name))

# File: .//examples/autogen/autogen.py
import asyncio
import os

from coagent.agents.chat_agent import ChatHistory, ChatMessage
from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    idle_loop,
    new,
    set_stderr_logger,
)
from coagent.runtimes import NATSRuntime
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.task import TextMentionTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_ext.models import AzureOpenAIChatCompletionClient


az_model_client = AzureOpenAIChatCompletionClient(
    model=os.getenv("AZURE_MODEL"),
    azure_endpoint=os.getenv("AZURE_API_BASE"),
    api_version=os.getenv("AZURE_API_VERSION"),
    api_key=os.getenv("AZURE_API_KEY"),
    model_capabilities={
        "vision": True,
        "function_calling": True,
        "json_output": True,
    },
)


# Define a tool
async def get_weather(city: str) -> str:
    return f"The weather in {city} is 73 degrees and Sunny."


class AutoGenWeatherAgent(BaseAgent):
    """Weather agent backed by AutoGen."""

    # Define an agent
    weather_agent = AssistantAgent(
        name="weather_agent",
        model_client=az_model_client,
        tools=[get_weather],
    )

    # Define termination condition
    termination = TextMentionTermination("TERMINATE")

    # Define a team
    agent_team = RoundRobinGroupChat([weather_agent], termination_condition=termination)

    @handler
    async def handle(self, msg: ChatHistory, ctx: Context) -> ChatHistory:
        # Run the team and return the result.
        result = await self.agent_team.run(task=msg.messages[-1].content)
        content = result.messages[-2].content
        msg.messages.append(ChatMessage(role="assistant", content=content))
        return msg


autogen = AgentSpec("autogen", new(AutoGenWeatherAgent))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(autogen)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    asyncio.run(main())

# File: .//examples/app-builder/team.py
import asyncio

from coagent.agents import Sequential
from coagent.core import AgentSpec, new, set_stderr_logger
from coagent.core.util import idle_loop
from coagent.runtimes import NATSRuntime


team = AgentSpec("team", new(Sequential, "dev", "qa"))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(team)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    asyncio.run(main())

# File: .//examples/app-builder/auto_team.py
import asyncio

from coagent.agents import ChatAgent, tool
from coagent.core import AgentSpec, idle_loop, new, set_stderr_logger
from coagent.runtimes import NATSRuntime


class AutoTeam(ChatAgent):
    system = """You are an manager who manages a team that consists of a dev agent and a qa agent.
    
    Your team is responsible for build software for users, and you should follow these rules:
    - Upon the request of the user, you should first transfer the conversation to the dev agent if the user requests to generate code.
    - When receiving the code from the dev agent, you should transfer the conversation to the qa agent.
    - Finally show the result from the qa agent to the user.
    """

    @tool
    async def transfer_to_dev(self):
        """The dev agent to generate the software code."""
        async for chunk in self.agent("dev"):
            yield chunk

    @tool
    async def transfer_to_qa(self):
        """The qa agent to review and refine the given software code."""
        async for chunk in self.agent("qa"):
            yield chunk


auto_team = AgentSpec("auto_team", new(AutoTeam))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(auto_team)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    asyncio.run(main())

# File: .//examples/app-builder/dev.py
import asyncio
from typing import AsyncIterator

from coagent.agents.chat_agent import ChatMessage
from coagent.agents.util import chat
from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    Message,
    new,
    set_stderr_logger,
)
from coagent.core.util import idle_loop, pretty_trace_agent_output
from coagent.runtimes import NATSRuntime


class ChatHistory(Message):
    messages: list[ChatMessage]


class DevEngineer(BaseAgent):
    system = """\
You are a Senior Software Engineer at a leading tech think tank.
Your expertise in programming in Python. and do your best to produce perfect code.\
"""
    task = """\
You will create a program using Python, these are the instructions:

Instructions
------------
{query}

Your Final answer must be the full python code, only the python code and nothing else.\
"""

    @handler
    async def handle(
        self, msg: ChatHistory, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        msgs = [
            ChatMessage(role="system", content=self.system),
            ChatMessage(
                role="user",
                content=self.task.format(
                    query=msg.messages[-1].content,
                ),
            ),
        ]

        reply = ""
        response = await chat(msgs, stream=True)
        async for chunk in response:
            yield ChatMessage(role="assistant", content=chunk.content)
            reply += chunk.content

        pretty_trace_agent_output("DevEngineer", reply)
        msg.messages.append(ChatMessage(role="user", content=reply))


dev = AgentSpec("dev", new(DevEngineer))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(dev)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    asyncio.run(main())

# File: .//examples/app-builder/qa.py
import asyncio
from typing import AsyncIterator

from coagent.agents.chat_agent import ChatMessage
from coagent.agents.util import chat
from coagent.core import (
    AgentSpec,
    BaseAgent,
    Context,
    handler,
    Message,
    new,
    set_stderr_logger,
)
from coagent.core.util import idle_loop, pretty_trace_agent_output
from coagent.runtimes import NATSRuntime


class ChatHistory(Message):
    messages: list[ChatMessage]


class QaEngineer(BaseAgent):
    system = """\
You are a Software Quality Control Engineer that specializes in checking code
for errors. You have an eye for detail and a knack for finding
hidden bugs.

You check for missing imports, variable declarations, mismatched brackets,
syntax errors and logic errors.\
"""
    task = """\
You will create a program using Python, these are the instructions:

Instructions
------------
{query}

Code
----
{code}

Using the code you got, check for errors. Check for logic errors,
syntax errors, missing imports, variable declarations, mismatched brackets,
and security vulnerabilities.

Your Final answer must be as below:
## Issues
Critical issues you found. If no issues found, write 'LGTM'.

## Code

The corrected version of full python code.\
"""

    @handler
    async def handle(
        self, msg: ChatHistory, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        msgs = [
            ChatMessage(role="system", content=self.system),
            ChatMessage(
                role="user",
                content=self.task.format(
                    query=msg.messages[-2].content,
                    code=msg.messages[-1].content,
                ),
            ),
        ]

        reply = ""
        response = await chat(msgs, stream=True)
        async for chunk in response:
            yield ChatMessage(role="assistant", content=chunk.content)
            reply += chunk.content

        pretty_trace_agent_output("QaEngineer", reply)
        msg.messages.append(ChatMessage(role="user", content=reply))


qa = AgentSpec("qa", new(QaEngineer))


async def main():
    async with NATSRuntime.from_servers() as runtime:
        await runtime.register(qa)
        await idle_loop()


if __name__ == "__main__":
    set_stderr_logger("TRACE")

    asyncio.run(main())

# File: .//coagent/core/discovery.py
from __future__ import annotations

import asyncio

from pydantic import BaseModel, Field

from .agent import BaseAgent, Context, handler, Operation
from .exceptions import AgentTypeNotFoundError
from .messages import Message
from .types import (
    Address,
    AgentSpec,
    RawMessage,
    Subscription,
)
from .util import Trie


SEPARATOR = "."


class Schema(BaseModel):
    """A schema of an agent."""

    name: str
    description: str = ""
    operations: list[Operation] = []

    def __lt__(self, other: Schema):
        # Sort by name
        return self.name < other.name


class DiscoveryQuery(Message):
    """A message to discover agents in a namespace."""

    namespace: str = Field(..., description="The namespace to discover agents in.")
    recursive: bool = Field(
        default=False,
        description="Whether to recursively discover agents in sub-namespaces.",
    )
    inclusive: bool = Field(
        default=False,
        description="Whether to include the agent whose name equals to the query namespace.",
    )
    detailed: bool = Field(
        default=False,
        description="Whether to return detailed operations for each agent.",
    )

    def matches(self, name: str) -> bool:
        """Check if the given name (agent type) matches the query."""

        if not name:
            # name is empty.
            return False

        if not name.startswith(self.namespace):
            # name is not under the namespace.
            return False

        if name == self.namespace:
            return self.inclusive

        name_level = len(name.split(SEPARATOR))
        namespace_level = len(self.namespace.split(SEPARATOR)) if self.namespace else 0
        if name_level == namespace_level + 1:
            return True

        # grandchild or great-grandchild, etc.
        return self.recursive


class DiscoveryReply(Message):
    """A reply message to a discover message."""

    agents: list[Schema]


class SubscribeToAgentUpdates(Message):
    """A message to subscribe to updates on the registration and deregistration
    of agents that match the given query.
    """

    sender: Address = Field(
        ..., description="The address of the agent initiating the subscription."
    )
    query: DiscoveryQuery


class UnsubscribeFromAgentUpdates(Message):
    """A message to unsubscribe from updates on the registration and deregistration
    of agents.
    """

    sender: Address = Field(
        ..., description="The address of the agent initiating the unsubscription."
    )


class AgentsRegistered(Message):
    """A message to notify that one or more agents have been registered."""

    agents: list[Schema] = Field(description="A list of agent schemas.")


class AgentsDeregistered(Message):
    """A message to notify that one or more agents have been deregistered."""

    agents: list[Schema] = Field(description="A list of agent schemas.")


class Discovery(BaseAgent):
    """A discovery agent that can discover agents in given namespaces.

    Internally, the agent acts as an aggregator. Upon receiving a discovery
    request, it will initiate a query to all discovery servers, and then
    aggregate the replies from these servers.
    """

    def __init__(self):
        super().__init__()

        # The local discovery server.
        self._server: DiscoveryServer | None = None

    async def start(self) -> None:
        """Since discovery is a special agent, we need to start it in a different way."""
        await super().start()

        # Create and start the local discovery server.
        self._server = DiscoveryServer()
        # We MUST set the channel and address manually.
        self._server.init(self.channel, Address(name=f"{self.address.name}.server"))
        await self._server.start()

    async def _create_subscription(self) -> Subscription:
        # Each query message can only be received and handled by one discovery aggregator.
        return await self.channel.subscribe(
            self.address,
            handler=self.receive,
            queue=f"{self.address.topic}_workers",
        )

    async def stop(self) -> None:
        """Since discovery is a special agent, we need to stop it in a different way."""
        if self._server:
            await self._server.stop()

        await super().stop()

    async def register(self, spec: AgentSpec) -> None:
        if spec.name == self.address.name:
            raise ValueError(f"Agent type '{self.address.name}' is reserved")

        if self._server:
            await self._server.register(spec)

    async def deregister(self, *names: str) -> None:
        if self._server:
            await self._server.deregister(*names)

    @handler
    async def discover(self, msg: DiscoveryQuery, ctx: Context) -> DiscoveryReply:
        """Discover agents in a given namespace in a distributed manner."""
        lock: asyncio.Lock = asyncio.Lock()
        agents: dict[str, Schema] = {}

        # TODO: Use QueueSubscriptionIterator to simplify this.
        async def receive(raw: RawMessage) -> None:
            # Gather
            reply = DiscoveryReply.decode(raw)
            if not reply.agents:
                return

            await lock.acquire()
            try:
                for agent in reply.agents:
                    agents[agent.name] = agent
            finally:
                lock.release()

        inbox = await self.channel.new_reply_topic()
        sub = await self.channel.subscribe(addr=Address(name=inbox), handler=receive)

        try:
            # Scatter
            await self.channel.publish(
                self._server.address,
                msg.encode(),
                request=True,
                reply=inbox,
                probe=False,
            )

            # Wait for all discovery servers to respond or timed out.
            # FIXME: How to get the original timeout specified by the publisher?
            await asyncio.sleep(0.45)  # Smaller than the default timeout (0.5s).

        finally:
            await sub.unsubscribe()

            sorted_agents = sorted(agents.values())
            return DiscoveryReply(agents=sorted_agents)

    @handler
    async def subscribe_to_agent_updates(
        self, msg: SubscribeToAgentUpdates, ctx: Context
    ) -> None:
        """Subscribe to updates on the registration and deregistration
        of agents that match the given query.
        """

        # Simply broadcast the message to all discovery servers.
        await self.channel.publish(self._server.address, msg.encode(), probe=False)

    @handler
    async def unsubscribe_from_agent_updates(
        self, msg: UnsubscribeFromAgentUpdates, ctx: Context
    ) -> None:
        """Unsubscribe from updates on the registration and deregistration
        of agents.
        """

        # Simply broadcast the message to all discovery servers.
        await self.channel.publish(self._server.address, msg.encode(), probe=False)


class _SynchronizeQuery(Message):
    """An internal message to synchronize agent-subscriptions from other discovery servers."""


class _SynchronizeReply(Message):
    """An internal reply message to a synchronize message."""

    subscriptions: dict[str, DiscoveryQuery] = Field(description="Agent subscriptions.")


class DiscoveryServer(BaseAgent):
    """A discovery server.

    When receiving a discovery query from the discovery aggregator, it will
    search locally for agents under the given namespace and return them to
    the discovery aggregator.
    """

    def __init__(self):
        super().__init__()

        self._agent_schemas: Trie = Trie(separator=SEPARATOR)
        self._agent_subscriptions: dict[Address, DiscoveryQuery] = {}

    async def start(self) -> None:
        """Since discovery server is a special agent, we need to start it in a different way."""
        await super().start()

        # Upon startup, the current discovery server has no agent-subscriptions.
        # Therefore, it's necessary to synchronize the existing agent-subscriptions
        # from other discovery servers.

        async def receive(raw: RawMessage) -> None:
            # Gather
            reply = _SynchronizeReply.decode(raw)
            for topic, query in reply.subscriptions.items():
                addr = Address.from_topic(topic)
                self._agent_subscriptions[addr] = query

        inbox = await self.channel.new_reply_topic()
        sub = await self.channel.subscribe(addr=Address(name=inbox), handler=receive)

        try:
            # Scatter
            await self.channel.publish(
                self.address,
                _SynchronizeQuery().encode(),
                request=True,
                reply=inbox,
                probe=False,
            )

            # Wait for all discovery servers to respond or timed out.
            await asyncio.sleep(0.2)  # TODO: Choose a better timeout.
        finally:
            await sub.unsubscribe()

    async def register(self, spec: AgentSpec) -> None:
        if spec.name == self.address.name:
            raise ValueError(f"Agent type '{self.address.name}' is reserved")
        if spec.name in self._agent_schemas:
            raise ValueError(f"Agent type '{spec.name}' already registered")

        operations = spec.constructor.type.collect_operations()
        description = spec.description or spec.constructor.type.__doc__ or ""
        schema = Schema(name=spec.name, description=description, operations=operations)
        self._agent_schemas[spec.name] = schema

        # Notify all subscribers about the registration of the new agent.
        for addr, query in self._agent_subscriptions.items():
            if query.matches(spec.name):
                msg = AgentsRegistered(
                    agents=[Schema(name=schema.name, description=schema.description)]
                )
                await self.channel.publish(addr, msg.encode())

    async def deregister(self, *names: str) -> None:
        candidate_names = []

        if names:
            for name in names:
                schema = self._agent_schemas.pop(name, None)
                if schema:
                    candidate_names.append(name)
        else:
            candidate_names = self._agent_schemas.keys()
            self._agent_schemas.clear()

        # Notify all subscribers about the deregistration of the involved agents.
        for addr, query in self._agent_subscriptions.items():
            matched_names = [name for name in candidate_names if query.matches(name)]
            if matched_names:
                msg = AgentsDeregistered(
                    agents=[Schema(name=name) for name in matched_names]
                )
                try:
                    await self.channel.publish(addr, msg.encode())
                except AgentTypeNotFoundError:
                    # The subscribing agent itself has been deregistered.
                    # Just ignore it.
                    pass

    @handler
    async def synchronize(
        self, msg: _SynchronizeQuery, ctx: Context
    ) -> _SynchronizeReply:
        subscriptions = {
            addr.topic: query for addr, query in self._agent_subscriptions.items()
        }
        return _SynchronizeReply(subscriptions=subscriptions)

    @handler
    async def search(self, msg: DiscoveryQuery, ctx: Context) -> DiscoveryReply:
        """
        Examples:

        given agents:
            a
            a.x
            a.x.0
            a.y
            a.y.0
            b
            b.x
            b.y
            b.z.0

        namespace="", recursive=False:
            a
            b

        namespace="", recursive=True:
            a
            a.x
            a.x.0
            a.y
            a.y.0
            b
            b.x
            b.y
            b.z.0

        namespace="a", recursive=False:
            a
            a.x
            a.y

        namespace="a", recursive=True:
            a
            a.x
            a.x.0
            a.y
            a.y.0

        namespace="b", recursive=False:
            b
            b.x
            b.y

        namespace="b", recursive=True:
            b
            b.x
            b.y
            b.z.0
        """
        if msg.recursive:
            try:
                namespace = msg.namespace or Trie.EMPTY
                schemas = self._agent_schemas.values(namespace)
            except KeyError:
                schemas = []
        else:
            schemas = self._agent_schemas.direct_values(msg.namespace)

        def filter_agent(schema: Schema) -> bool:
            if not schema:
                return False
            if not msg.inclusive:
                return schema.name != msg.namespace
            return True

        agents = [
            Schema(
                name=schema.name,
                description=schema.description,
                operations=schema.operations if msg.detailed else [],
            )
            for schema in schemas
            if filter_agent(schema)
        ]
        return DiscoveryReply(agents=agents)

    @handler
    async def subscribe_to_agent_updates(
        self, msg: SubscribeToAgentUpdates, ctx: Context
    ) -> None:
        self._agent_subscriptions[msg.sender] = msg.query

    @handler
    async def unsubscribe_from_agent_updates(
        self, msg: UnsubscribeFromAgentUpdates, ctx: Context
    ) -> None:
        self._agent_subscriptions.pop(msg.sender, None)

# File: .//coagent/core/util.py
import asyncio
import os
import signal
from typing import Any, get_type_hints

import pygtrie

from .logger import logger


class Trie(pygtrie.StringTrie):
    EMPTY = pygtrie._EMPTY

    def direct_items(self, prefix: str) -> list[tuple[str, Any]]:
        """Return items directly under the given prefix."""

        max_level: int = len(prefix.split(self._separator)) if prefix else 0
        items: list[tuple[str, Any]] = []

        def traverse_callback(path_conv, path, children, value=None):
            key = path_conv(path)
            if key.startswith(prefix):
                items.append((key, value))

            if len(path) <= max_level:
                # Traverse into the children of the current node.
                list(children)

        self.traverse(traverse_callback)
        return items

    def direct_keys(self, prefix: str) -> list[str]:
        keys: list[str] = []
        for key, _ in self.direct_items(prefix):
            keys.append(key)
        return keys

    def direct_values(self, prefix: str) -> list[Any]:
        values: list[Any] = []
        for _, value in self.direct_items(prefix):
            values.append(value)
        return values


def get_func_args(func) -> set[str]:
    if hasattr(func, "__mcp_tool_args__"):
        return set(func.__mcp_tool_args__)

    hints = get_type_hints(func)
    hints.pop("return", None)  # Ignore the return type.
    return set(hints.keys())


async def clear_queue(queue: asyncio.Queue) -> None:
    """Clear the given queue."""

    # Drain all the remaining items in the queue.
    #
    # We can change to `queue.shutdown(immediate=True)` in Python 3.13+
    while not queue.empty():
        try:
            queue.get_nowait()
            queue.task_done()
        except asyncio.QueueEmpty:
            break


async def idle_loop():
    try:
        stop_event = asyncio.Event()

        loop = asyncio.get_event_loop()
        loop.add_signal_handler(signal.SIGINT, stop_event.set)

        while not stop_event.is_set():
            await asyncio.sleep(1)

    except asyncio.CancelledError:
        pass


def exit_loop():
    os.kill(os.getpid(), signal.SIGINT)


def pretty_trace_agent_output(name: str, content: str):
    logger.opt(colors=True).trace(
        f"<green>{name}</green> =>\n\n<magenta>{content}</magenta>"
    )


def pretty_trace_tool_call(name: str, args: dict[str, any]):
    args_str = ", ".join(f"{k}={v!r}" for k, v in args.items())
    logger.opt(colors=True).trace(
        f"<green>{name}</green><magenta>({args_str})</magenta>"
    )

# File: .//coagent/core/__init__.py
# ruff: noqa: F401
from .agent import (
    BaseAgent,
    Context,
    handler,
)
from .discovery import DiscoveryQuery, DiscoveryReply
from .logger import logger, set_stderr_logger
from .messages import Message, GenericMessage, SetReplyInfo, StopIteration
from .runtime import BaseRuntime, BaseChannel, QueueSubscriptionIterator
from .types import (
    Address,
    Agent,
    AgentSpec,
    Constructor,
    Channel,
    MessageHeader,
    new,
    NO_REPLY,
    RawMessage,
    Reply,
    Subscription,
)
from .util import idle_loop

# File: .//coagent/core/types.py
from __future__ import annotations

import abc
import dataclasses
import enum
from typing import Any, AsyncIterator, Awaitable, Callable, Type
import uuid

from pydantic import BaseModel, Field


# Mapping from singleton agent type to coagent topic.
agent_types_to_topics = {
    "discovery": "coagent.discovery",
    "discovery.server": "coagent.discovery.server",
}
# Mapping from coagent topic to singleton agent type.
topics_to_agent_types = {v: k for k, v in agent_types_to_topics.items()}

coagent_factory_topic_prefix = "coagent.factory."
coagent_agent_topic_prefix = "coagent.agent."
coagent_reply_topic_prefix = (
    "_INBOX."  # Actually this is the reply topic prefix of NATS.
)


class Address(BaseModel):
    name: str = Field(description="Agent type")
    id: str = Field(default="", description="Session ID")

    def __hash__(self):
        return hash(self.topic)

    def __eq__(self, other: Address | None):
        if other is None:
            return False
        return self.topic == other.topic

    @property
    def is_reply(self) -> bool:
        return self.name.startswith(coagent_reply_topic_prefix)

    @property
    def topic(self) -> str:
        # For a singleton agent.
        _topic = agent_types_to_topics.get(self.name)
        if _topic:
            return _topic

        if self.is_reply:
            return self.name

        if self.id:
            # Normal agent.
            return f"{coagent_agent_topic_prefix}{self.name}.{self.id}"
        else:
            # Factory agent.
            return f"{coagent_factory_topic_prefix}{self.name}"

    @classmethod
    def from_topic(cls, topic: str) -> Address:
        # For a singleton agent.
        agent_type = topics_to_agent_types.get(topic)
        if agent_type:
            return cls(name=agent_type)

        if topic.startswith(coagent_reply_topic_prefix):
            return cls(name=topic)

        if topic.startswith(coagent_agent_topic_prefix):
            relative_topic = topic.removeprefix(coagent_agent_topic_prefix)
        elif topic.startswith(coagent_factory_topic_prefix):
            relative_topic = topic.removeprefix(coagent_factory_topic_prefix)
        else:
            raise ValueError(f"Invalid topic: {topic}")

        words = relative_topic.split(".", 1)
        if len(words) == 1:
            return cls(name=words[0])
        else:  # len(words) == 2
            return cls(name=words[0], id=words[1])

    def encode(self, mode: str = "python") -> dict:
        return self.model_dump(mode=mode)

    @classmethod
    def decode(cls, data: dict) -> Address:
        return cls.model_validate(data)


class Reply(BaseModel):
    address: Address = Field(..., description="Reply address.")
    stream: bool = Field(
        False, description="Whether the sender requests a streaming result."
    )


# A sentinel reply object that indicates no reply will be sent.
#
# This is mainly used by the orchestration agents who delegate the reply
# handling to other agents.
NO_REPLY = Reply(address=Address(name="", id=""), stream=False)


class MessageHeader(BaseModel):
    type: str = Field(..., description="Message type name.")
    content_type: str = Field(
        default="application/json", description="Message content type."
    )
    extensions: dict = Field(default_factory=dict, description="Extension fields.")


class RawMessage(BaseModel):
    header: MessageHeader = Field(..., description="Message header.")
    reply: Reply | None = Field(default=None, description="Reply information.")
    content: bytes = Field(default=b"", description="Message content.")

    def encode(self, mode: str = "python", exclude_defaults: bool = True) -> dict:
        return self.model_dump(mode=mode, exclude_defaults=exclude_defaults)

    @classmethod
    def decode(cls, data: dict) -> RawMessage:
        return cls.model_validate(data)

    def encode_json(self, exclude_defaults: bool = True) -> str:
        return self.model_dump_json(exclude_defaults=exclude_defaults)

    @classmethod
    def decode_json(cls, json_data: str | bytes) -> RawMessage:
        return cls.model_validate_json(json_data)


class Constructor:
    def __init__(self, typ: Type, *args: Any, **kwargs: Any) -> None:
        self.type: Type = typ
        self.args: tuple[Any] = args
        self.kwargs: dict[str, Any] = kwargs

        # When a `__post_call__()` method is defined on the class, it will be
        # called by `__call__()`, normally as `self.__post_call__(agent)`.
        self._post_call_fn: Callable[[Agent], Awaitable[None]] | None = getattr(
            self, "__post_call__", None
        )

    async def __call__(
        self, channel: Channel, address: Address, factory_address: Address | None = None
    ) -> Agent:
        agent = self.type(*self.args, **self.kwargs)
        agent.init(channel, address, factory_address)

        if self._post_call_fn is not None:
            await self._post_call_fn(agent)

        return agent


# new is a shortcut for Constructor.
new = Constructor


class State(str, enum.Enum):
    STARTED = "started"
    RUNNING = "running"
    IDLE = "idle"  # Only this state is actually used for now.
    STOPPED = "stopped"


class Agent(abc.ABC):
    @property
    @abc.abstractmethod
    def id(self) -> str:
        """Return the unique ID of the agent."""
        pass

    @abc.abstractmethod
    def init(
        self, channel: Channel, address: Address, factory_address: Address | None = None
    ) -> None:
        """Initialize the agent with the given channel and address."""
        pass

    @abc.abstractmethod
    async def get_state(self) -> State:
        """Get the current state of the agent."""
        pass

    @abc.abstractmethod
    async def start(self) -> None:
        """Start the current agent."""
        pass

    @abc.abstractmethod
    async def stop(self) -> None:
        """Stop the current agent."""
        pass

    @abc.abstractmethod
    async def delete(self) -> None:
        """Request to delete the current agent."""
        pass

    @abc.abstractmethod
    async def started(self) -> None:
        """This handler is called after the agent is started."""
        pass

    @abc.abstractmethod
    async def stopped(self) -> None:
        """This handler is called after the agent is stopped."""
        pass

    @abc.abstractmethod
    async def receive(self, raw: RawMessage) -> None:
        """Handle the incoming raw message."""
        pass


class Subscription(abc.ABC):
    @abc.abstractmethod
    async def unsubscribe(self, limit: int = 0) -> None:
        """Align to NATS for simplicity."""
        pass


class Channel(abc.ABC):
    @abc.abstractmethod
    async def connect(self) -> None:
        pass

    @abc.abstractmethod
    async def close(self) -> None:
        pass

    @abc.abstractmethod
    async def publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> AsyncIterator[RawMessage] | RawMessage | None:
        """Publish a message to the given address.

        Args:
            addr (Address): The address of the agent.
            msg (RawMessage): The raw message to send.
            stream (bool, optional): Whether to request a streaming result. Defaults to False.
            request (bool, optional): Whether this is a request. Defaults to False. If `stream` is True, then this is always True.
            reply (str, optional): If `request` is True, then this will be the subject to reply to. Defaults to "".
            timeout (float, optional): If `request` is True, then this will be the timeout for the response. Defaults to 0.5.
            probe (bool, optional): Whether to probe the agent before sending the message. Defaults to True.
        """
        pass

    @abc.abstractmethod
    async def subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]],
        queue: str = "",
    ) -> Subscription:
        pass

    @abc.abstractmethod
    async def new_reply_topic(self) -> str:
        pass

    @abc.abstractmethod
    async def cancel(self, addr: Address) -> None:
        """Cancel the agent with the given address."""
        pass


@dataclasses.dataclass
class AgentSpec:
    """The specification of an agent."""

    name: str
    constructor: Constructor
    description: str = ""

    __runtime: Runtime | None = dataclasses.field(default=None, init=False)

    def register(self, runtime: Runtime) -> None:
        """Register the agent specification to a runtime."""
        self.__runtime = runtime

    async def run(
        self,
        msg: RawMessage,
        stream: bool = False,
        session_id: str = "",
        timeout: float = 0.5,
    ) -> AsyncIterator[RawMessage] | RawMessage | None:
        """Create an agent and run it with the given message."""
        if self.__runtime is None:
            raise ValueError(f"AgentSpec {self.name} is not registered to a runtime.")

        session_id = session_id or uuid.uuid4().hex
        addr = Address(name=self.name, id=session_id)

        return await self.__runtime.channel.publish(
            addr, msg, stream=stream, request=True, timeout=timeout
        )


class Runtime(abc.ABC):
    async def __aenter__(self):
        await self.start()
        return self

    async def __aexit__(self, exc_type, exc, tb):
        await self.stop()

    @abc.abstractmethod
    async def start(self) -> None:
        pass

    @abc.abstractmethod
    async def stop(self) -> None:
        pass

    @abc.abstractmethod
    async def register(self, spec: AgentSpec) -> None:
        pass

    @abc.abstractmethod
    async def deregister(self, *names: str) -> None:
        pass

    @property
    @abc.abstractmethod
    def channel(self) -> Channel:
        pass

# File: .//coagent/core/logger.py
import sys

from loguru import logger


def set_stderr_logger(level: str = "INFO"):
    logger.remove()
    logger.add(
        sys.stderr,
        level=level,
        format="<level>{level: <8}</level> | <level>{message}</level>",
    )
    logger.level("DEBUG", color="<fg 128,128,128>")

# File: .//coagent/core/factory.py
import asyncio
import uuid

from .agent import BaseAgent, Context, handler
from .logger import logger
from .messages import Message
from .types import (
    Address,
    Agent,
    AgentSpec,
    State,
    Subscription,
)


class CreateAgent(Message):
    """A message to create an agent associated with a session ID."""

    session_id: str


class DeleteAgent(Message):
    """A message to delete an agent associated with a session ID."""

    session_id: str


class Factory(BaseAgent):
    """A factory is a special agent that manages one type of primitive agents.

    Therefore, it is a singleton agent for each type of primitive agents and
    its address is corresponding with the name of the agent type.
    """

    def __init__(self, spec: AgentSpec) -> None:
        super().__init__()

        self._spec: AgentSpec = spec

        self._agents: dict[Address, Agent] = {}
        self._lock: asyncio.Lock = asyncio.Lock()

        # Instance subscription for the current factory agent.
        #
        # Note that there are two types of subscriptions:
        #
        # 1. `self._sub`: The subscription for receiving CreateAgent messages to
        #    create new agents. This subscription is created by `self._create_subscription`,
        #    and multiple subscriptions work in load balancing mode. That is, each
        #    CreateAgent message will be randomly distributed to one of the factory agents.
        #
        # 2. `self._instance_sub`: The subscription for receiving messages
        #    specifically to the current factory agent instance. For example,
        #    the factory agent instance will receive DeleteAgent messages to
        #    delete agents created by itself.
        self._instance_address: Address | None = None
        self._instance_sub: Subscription | None = None

        self._recycle_task: asyncio.Task | None = None

    async def start(self) -> None:
        """Since factory is a special agent, we need to start it in a different way."""
        await super().start()

        # Generate a unique address and create an instance subscription.
        unique_id = uuid.uuid4().hex
        self._instance_address = Address(name=f"{self.address.name}_{unique_id}")
        self._instance_sub = await self.channel.subscribe(
            self._instance_address, handler=self.receive
        )

        # Start the recycle loop.
        self._recycle_task = asyncio.create_task(self._recycle())

    async def _create_subscription(self) -> Subscription:
        # Each CreateAgent message can only be received and handled by one of
        # the factory agents.
        #
        # Note that we specify a queue parameter to distribute requests among
        # multiple factory agents of the same type of primitive agent.
        return await self.channel.subscribe(
            self.address,
            handler=self.receive,
            queue=f"{self.address.topic}_workers",
        )

    async def stop(self) -> None:
        """Since factory is a special agent, we need to stop it in a different way."""
        # Delete all agents.
        for agent in self._agents.values():
            await agent.stop()
        self._agents.clear()

        # Cancel the recycle loop.
        if self._recycle_task:
            self._recycle_task.cancel()

        if self._instance_sub:
            await self._instance_sub.unsubscribe()

        await super().stop()

    async def _recycle(self) -> None:
        """The recycle loop for deleting idle agents."""
        while True:
            # Recycle every 20 seconds.
            # TODO: Make the recycle interval configurable.
            await asyncio.sleep(20)

            total_num: int = 0
            idle_agents: list[Address] = []

            async with self._lock:
                for addr, agent in self._agents.items():
                    total_num += 1
                    state = await agent.get_state()
                    if state == State.IDLE:
                        idle_agents.append(addr)

            idle_num = len(idle_agents)
            if not idle_num:
                continue

            running_num = total_num - idle_num
            logger.debug(
                f"[Factory {self.id}] Recycling agents: {running_num} running, {idle_num} idle"
            )

            deleted_agents: list[Agent] = []
            async with self._lock:
                for addr in idle_agents:
                    agent = self._agents.pop(addr, None)
                    if agent:
                        deleted_agents.append(agent)

            for agent in deleted_agents:
                await agent.stop()

    @handler
    async def create_agent(self, msg: CreateAgent, ctx: Context) -> None:
        async with self._lock:
            addr = Address(name=self.address.name, id=msg.session_id)
            if addr in self._agents:
                return

            # Create an agent with the given channel, address and factory address.
            agent = await self._spec.constructor(
                self.channel, addr, self._instance_address
            )
            self._agents[addr] = agent

            await agent.start()

    @handler
    async def delete_agent(self, msg: DeleteAgent, ctx: Context) -> None:
        async with self._lock:
            addr = Address(name=self.address.name, id=msg.session_id)
            agent = self._agents.pop(addr, None)
            if agent:
                await agent.stop()

# File: .//coagent/core/runtime.py
import abc
import asyncio
from typing import AsyncIterator

import pydantic

from .discovery import Discovery
from .exceptions import BaseError
from .messages import Cancel, Error, StopIteration
from .factory import Factory
from .types import (
    AgentSpec,
    Channel,
    Runtime,
    Address,
    RawMessage,
)


class BaseRuntime(Runtime):
    def __init__(self, channel: Channel):
        self._channel: Channel = channel
        self._discovery: Discovery | None = None
        self._factories: dict[str, Factory] = {}

    async def start(self) -> None:
        await self._channel.connect()

        self._discovery = Discovery()
        # We MUST set the channel and address manually.
        self._discovery.init(self._channel, Address(name="discovery"))
        await self._discovery.start()

    async def stop(self) -> None:
        await self._discovery.stop()
        await self.deregister()
        await self._channel.close()

    async def register(self, spec: AgentSpec) -> None:
        spec.register(self)

        if self._discovery:
            await self._discovery.register(spec)

        if spec.name in self._factories:
            raise ValueError(f"Agent type {spec.name} already registered")

        factory = Factory(spec)
        # We MUST set the channel and address manually.
        factory.init(self._channel, Address(name=spec.name))
        self._factories[spec.name] = factory

        await factory.start()

    async def deregister(self, *names: str) -> None:
        if names:
            for name in names:
                factory = self._factories.pop(name, None)
                if factory:
                    await factory.stop()
        else:
            for factory in self._factories.values():
                await factory.stop()
            self._factories.clear()

        if self._discovery:
            await self._discovery.deregister(*names)

    @property
    def channel(self) -> Channel:
        return self._channel


class BaseChannel(Channel):
    async def publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> AsyncIterator[RawMessage] | RawMessage | None:
        if stream:
            return self._publish_stream(addr, msg, probe=probe)
        else:
            return await self._publish(
                addr,
                msg,
                request=request,
                stream=stream,
                reply=reply,
                timeout=timeout,
                probe=probe,
            )

    @abc.abstractmethod
    async def _publish(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool = False,
        stream: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> RawMessage | None:
        pass

    async def _publish_stream(
        self,
        addr: Address,
        msg: RawMessage,
        probe: bool = True,
    ) -> AsyncIterator[RawMessage]:
        """Publish a message and wait for multiple reply messages.

        Args:
            addr (Address): The address of the agent.
            msg (RawMessage): The raw message to send.
            probe (bool, optional): Whether to probe the agent before sending the message. Defaults to True.

        This is a default implementation that leverages the channel's own subscribe and _publish methods.
        """
        queue: QueueSubscriptionIterator = QueueSubscriptionIterator()

        inbox = await self.new_reply_topic()
        sub = await self.subscribe(addr=Address(name=inbox), handler=queue.receive)

        await self._publish(
            addr,
            msg,
            stream=True,
            request=True,
            reply=inbox,
            probe=probe,
        )

        try:
            async for msg in queue:
                try:
                    err = Error.decode(msg)
                    raise BaseError.decode_message(err)
                except pydantic.ValidationError:
                    yield msg
        finally:
            await sub.unsubscribe()

    async def cancel(self, addr: Address) -> None:
        """Cancel the agent with the given address."""

        # A shortcut for sending a Cancel message to the agent.
        await self.publish(addr, Cancel().encode(), probe=False)


class QueueSubscriptionIterator:
    """A Queue-based async iterator that receives messages from a subscription and yields them."""

    def __init__(self):
        self.queue: asyncio.Queue[RawMessage] = asyncio.Queue()

    async def receive(self, raw: RawMessage) -> None:
        await self.queue.put(raw)

    async def __anext__(self) -> RawMessage:
        msg = await self.queue.get()
        self.queue.task_done()
        try:
            # If it's a StopIteration message, end the iteration.
            StopIteration.decode(msg)
            raise StopAsyncIteration
        except pydantic.ValidationError:
            try:
                err = Error.decode(msg)
                raise BaseError.decode_message(err)
            except pydantic.ValidationError:
                return msg

    def __aiter__(self):
        return self

# File: .//coagent/core/agent.py
import asyncio
import inspect
import time
from typing import Any, AsyncIterator, Awaitable, Callable, Type, get_type_hints, cast

from pydantic import BaseModel, ValidationError

from .exceptions import MessageDecodeError, InternalError, StreamError
from .logger import logger
from .messages import (
    Cancel,
    ControlMessage,
    Empty,
    ProbeAgent,
    Message,
    Started,
    Stopped,
    SetReplyInfo,
    StopIteration,
)
from .types import (
    Address,
    Agent,
    Channel,
    NO_REPLY,
    RawMessage,
    Reply,
    State,
    Subscription,
)


class Context:
    pass


def get_type_name(typ: Type[Any]) -> str:
    return f"{typ.__module__}.{typ.__qualname__}"


def handler(func):
    """Decorator to mark the given function as a message handler.

    This decorator is typically used on methods of an agent class, and the method must have 3 arguments:
        1. `self`
        2. `msg`: The message to be handled, this must be type-hinted with the message type that it is intended to handle.
        3. `ctx`: A Context object.
    """
    hints = get_type_hints(func)
    return_type = hints.pop("return", None)  # Ignore the return type.
    if len(hints) != 2:
        raise AssertionError(
            "The handler method must have 3 arguments: (self, msg, ctx)"
        )

    params = list(hints.items())
    msg_name, msg_type = params[0]
    ctx_name, ctx_type = params[1]

    if not issubclass(msg_type, Message):
        want, got = get_type_name(Message), get_type_name(msg_type)
        raise AssertionError(
            f"The argument '{msg_name}' must be type-hinted with a subclass of `{want}` type (got `{got}`)"
        )

    if ctx_type is not Context:
        want, got = get_type_name(Context), get_type_name(ctx_type)
        raise AssertionError(
            f"The argument '{ctx_name}' must be type-hinted with a `{want}` type (got `{got}`)"
        )

    func.is_message_handler = True
    func.target_message_type = msg_type
    func.return_type = get_return_type(return_type)
    return func


def get_return_type(typ: Type[Any]) -> Type[Any]:
    if hasattr(typ, "__origin__") and issubclass(typ.__origin__, AsyncIterator):
        if hasattr(typ, "__args__"):
            # Extract the inner type T from `AsyncIterator[T]`.
            return typ.__args__[0]

    return typ


Handler = Callable[[Any, Any, Any], Any]


class Operation(BaseModel):
    """Operation represents a message handler of the corresponding agent."""

    name: str
    description: str
    message: dict
    reply: dict


class BaseAgent(Agent):
    """BaseAgent is the base class for all agents.

    Args:
        timeout (float, optional): The inactivity timeout for transitioning the
            agent state from RUNNING to IDLE. Defaults to 60 (in seconds).

            If the agent is not receiving any messages within this duration, it
            will be transitioned to the IDLE state. Once in the IDLE state, the
            agent will be deleted (recycled) by its corresponding factory agent.
    """

    def __init__(self, timeout: float = 60):
        # The following attributes will be set by the runtime after agent creation.
        self.channel: Channel | None = None
        self.address: Address | None = None
        self.factory_address: Address | None = None

        self._sub: Subscription | None = None

        # The task for handling DATA messages.
        self._handle_data_task: asyncio.Task | None = None
        self._pending_queue: asyncio.Queue[Message] = asyncio.Queue()

        self._timeout: float = timeout
        self._last_msg_received_at: float = time.time()

        # A lock to protect the access to `self._last_msg_received_at`, which
        # will be written to when receiving messages and read from when getting
        # the state of this agent.
        #
        # Note that it's possible to avoid using locks if the factory agent
        # gets the state of this agent through sending query messages, but
        # this would result in a lot of messages.
        self._last_msg_received_at_lock: asyncio.Lock = asyncio.Lock()

        # Normally `reply` is set by an orchestration agent by sending a `SetReplyInfo` message.
        self.reply: Reply | None = None
        self._reply_lock: asyncio.Lock = asyncio.Lock()

        handlers, message_types = self.__collect_handlers()
        # A list of handlers that are registered to handle messages.
        self._handlers: dict[Type, Handler] = handlers
        # A list of message types associated with this agent.
        self._message_types: dict[str, Type[Message]] = {
            "Cancel": Cancel,
            "Started": Started,
            "Stopped": Stopped,
            "SetReplyInfo": SetReplyInfo,
            "ProbeAgent": ProbeAgent,
            "Empty": Empty,
            **message_types,
        }

    @property
    def id(self) -> str:
        if self.address.id:
            return f"{self.address.name}.{self.address.id}"
        else:
            return self.address.name

    def init(
        self, channel: Channel, address: Address, factory_address: Address | None = None
    ) -> None:
        self.channel = channel
        self.address = address
        self.factory_address = factory_address

    async def get_state(self) -> State:
        async with self._last_msg_received_at_lock:
            elapsed = time.time() - self._last_msg_received_at

        if elapsed >= self._timeout:
            return State.IDLE
        return State.RUNNING

    async def start(self) -> None:
        """Start the current agent."""

        # Subscribe the agent to its own address.
        self._sub = await self._create_subscription()

        # Send a `Started` message to the current agent.
        await self.channel.publish(self.address, Started().encode(), probe=False)

        if not self._handle_data_task:
            self._handle_data_task = asyncio.create_task(self._handle_data())

    async def _create_subscription(self) -> Subscription:
        # Subscribe the agent's receive method to its own address.
        return await self.channel.subscribe(self.address, handler=self.receive)

    async def stop(self) -> None:
        """Stop the current agent."""

        # Send a `Stopped` message to the current agent.
        await self.channel.publish(self.address, Stopped().encode(), probe=False)

        # Unsubscribe the agent from its own address.
        if self._sub:
            await self._sub.unsubscribe()

        if self._handle_data_task:
            self._handle_data_task.cancel()

    async def delete(self) -> None:
        """Request to delete the current agent."""
        from .factory import DeleteAgent

        if self.factory_address:
            msg = DeleteAgent(session_id=self.address.id).encode()
            await self.channel.publish(self.factory_address, msg, probe=False)

    async def started(self) -> None:
        """This handler is called after the agent is started."""
        pass

    async def stopped(self) -> None:
        """This handler is called after the agent is stopped."""
        pass

    async def receive(self, raw: RawMessage) -> None:
        name: str = f"{self.__class__.__name__} {self.id}"
        logger.debug(f"[{name}] Received a message: {raw.model_dump()}")

        async with self._last_msg_received_at_lock:
            self._last_msg_received_at = time.time()

        msg_type_name = raw.header.type
        msg_type = self._message_types.get(msg_type_name)
        if not msg_type:
            # If the message type is not found, try to use the generic message.
            msg_type = self._message_types.get("GenericMessage")
            if not msg_type:
                err = MessageDecodeError(f"message type '{msg_type_name}' not found")
                sent = await self.__send_reply(raw.reply, err.encode_message())
                if not sent:
                    logger.error(f"Failed to decode message: {err}")
                return

        try:
            msg = msg_type.decode(raw)
        except ValidationError as exc:
            err = MessageDecodeError(str(exc))
            sent = await self.__send_reply(raw.reply, err.encode_message())
            if not sent:
                logger.error(f"Failed to decode message: {err}")
            return

        if isinstance(msg, ControlMessage):
            await self._handle_control(msg)
        else:
            await self._pending_queue.put(msg)

    async def _handle_control(self, msg: ControlMessage) -> None:
        """Handle CONTROL messages."""
        match msg:
            case Cancel():
                # Delete the agent when cancelled.
                await self.delete()
            case _:
                await self._handle_control_custom(msg, Context())

    async def _handle_control_custom(self, msg: ControlMessage, ctx: Context) -> None:
        """Handle user-defined CONTROL messages."""
        h: Handler = self.__get_handler(msg)
        # By design, CONTROL messages are management commands that must be
        # processed instantly and do not wait for any return value.
        await h(self, msg, ctx)

    async def _handle_data(self) -> None:
        """Handle DATA messages."""
        while True:
            msg = await self._pending_queue.get()
            self._pending_queue.task_done()

            match msg:
                case Started():
                    await self.started()

                case Stopped():
                    await self.stopped()

                case SetReplyInfo():
                    await self._set_reply_info(msg.reply_info)

                case ProbeAgent() | Empty():
                    # Do not handle probes and empty messages.
                    pass

                case _:
                    await self._handle_data_custom(msg, Context())

    async def _handle_data_custom(self, msg: Message, ctx: Context) -> None:
        """Handle user-defined DATA messages."""
        h: Handler = self.__get_handler(msg)
        result = h(self, msg, ctx)
        await self.__send_reply(msg.reply, result)

    async def _get_reply_info(self) -> Reply | None:
        async with self._reply_lock:
            return self.reply

    async def _set_reply_info(self, reply_info: Reply) -> None:
        async with self._reply_lock:
            self.reply = reply_info

    async def __send_reply(
        self,
        in_msg_reply: Reply,
        result: Message | Awaitable[Message] | AsyncIterator[Message],
    ) -> bool:
        reply = await self._get_reply_info() or in_msg_reply
        await self.send_reply(reply, result)
        sent = reply and reply is not NO_REPLY
        return sent

    async def send_reply(
        self,
        to: Reply,
        result: Message | Awaitable[Message] | AsyncIterator[Message],
    ) -> None:
        async def pub(msg: Message):
            if to and to is not NO_REPLY:
                await self.channel.publish(to.address, msg.encode())

        async def pub_exc(exc: BaseException):
            err = InternalError.from_exception(exc)
            await pub(err.encode_message())

        if to and to.stream:  # Streaming mode
            try:
                if is_async_iterator(result):
                    async for msg in result:
                        await pub(msg)
                elif inspect.isawaitable(result):
                    msg = await result or Empty()
                    await pub(msg)
                else:
                    await pub(result)
            except asyncio.CancelledError as exc:
                await pub_exc(exc)
                raise
            except Exception as exc:
                await pub_exc(exc)
            finally:
                # End of the iteration, send an extra StopIteration message.
                await pub(StopIteration())
        else:  # None, NO_REPLY, or non-streaming
            try:
                if is_async_iterator(result):
                    accumulated: RawMessage | None = None
                    async for msg in result:
                        if not accumulated:
                            accumulated = msg
                        else:
                            try:
                                accumulated += msg
                            except TypeError:
                                await pub_exc(StreamError("Streaming mode is required"))
                    await pub(accumulated)
                elif inspect.isawaitable(result):
                    msg = await result or Empty()
                    await pub(msg)
                else:
                    await pub(result)
            except asyncio.CancelledError as exc:
                await pub_exc(exc)
                raise
            except Exception as exc:
                await pub_exc(exc)

    def __get_handler(self, msg: Message) -> Handler | None:
        msg_type: Type[Any] = type(msg)

        # Try to find a handler specific to the exact message type.
        h = self._handlers.get(msg_type)
        if not h:
            # Use the handler for all messages, if there is one.
            h = self._handlers.get(Message)

        return h

    @classmethod
    def __collect_handlers(cls) -> tuple[dict[Type, Handler], dict[str, Type[Message]]]:
        handlers: dict[Type, Handler] = {}
        message_types: dict[str, Type[Message]] = {}
        for attr in dir(cls):
            if callable(getattr(cls, attr, None)):
                h = getattr(cls, attr)
                if hasattr(h, "is_message_handler"):
                    handlers[h.target_message_type] = cast(Handler, h)
                    message_types[h.target_message_type.__name__] = (
                        h.target_message_type
                    )
                    if h.return_type:
                        message_types[h.return_type.__name__] = h.return_type
        return handlers, message_types

    @classmethod
    def collect_operations(cls) -> list[Operation]:
        handlers: dict[Type, Handler] = cls.__collect_handlers()[0]
        operations = []
        for h in handlers.values():
            operations.append(
                Operation(
                    name=h.__name__,
                    description=h.__doc__ or h.__name__,
                    message=h.target_message_type.model_json_schema(),
                    reply=h.return_type.model_json_schema()
                    if h.return_type is not type(None)
                    else {},
                )
            )
        return operations


def is_async_iterator(obj) -> bool:
    """Check if obj is an async-iterator."""
    return hasattr(obj, "__aiter__") and hasattr(obj, "__anext__")

# File: .//coagent/core/messages.py
from __future__ import annotations

import json
from pydantic import BaseModel, ConfigDict, Field, ValidationError

from .types import MessageHeader, RawMessage, Reply


class Message(BaseModel):
    model_config = ConfigDict(extra="forbid")

    reply: Reply | None = Field(default=None, description="Reply information.")
    extensions: dict = Field(
        default_factory=dict, description="Extension fields from RawMessage header."
    )

    def __add__(self, other: Message) -> Message:
        """Concatenate two messages.

        This binary operator is mainly used to aggregate multiple streaming
        messages into one message when the sender requests to receive a
        non-streaming result.
        """
        return NotImplemented

    def encode(
        self, content_type: str = "application/json", exclude_defaults: bool = True
    ) -> RawMessage:
        if not content_type == "application/json":
            raise ValidationError.from_exception_data("Invalid content type", [])

        content = self.model_dump_json(
            exclude={"reply", "extensions"},
            exclude_defaults=exclude_defaults,
        )
        if content == "{}":
            content = ""

        return RawMessage(
            header=MessageHeader(
                type=self.__class__.__name__,
                content_type=content_type,
                extensions=self.extensions,
            ),
            content=content.encode("utf-8"),
        )

    @classmethod
    def decode(cls, raw: RawMessage) -> Message:
        if raw.header.type != cls.__name__:
            raise ValidationError.from_exception_data("Invalid message type", [])

        if not raw.header.content_type == "application/json":
            raise ValidationError.from_exception_data("Invalid content type", [])

        data = {"reply": raw.reply, "extensions": raw.header.extensions}
        if raw.content:
            try:
                data.update(json.loads(raw.content.decode("utf-8")))
            except json.JSONDecodeError as exc:
                raise ValidationError.from_exception_data(str(exc), [])

        return cls.model_validate(data)


class ControlMessage(Message):
    """ControlMessage is the base class for all control messages.

    A control message is used to control the behavior of an agent. For example,
    a `Cancel` message can be sent to an agent to cancel the processing of the
    agent and delete it.

    For a specific agent, CONTROL messages and DATA messages are processed in
    separate coroutines, so CONTROL messages can be processed in a timely manner
    without being blocked by DATA messages. By design, CONTROL messages are
    management commands that must be processed instantly and do not wait for
    any return value.

    Any CONTROL message should be a subclass of this class. And any other messages,
    inherited from `Message`, are DATA messages.
    """

    pass


class Cancel(ControlMessage):
    """A control message to cancel the processing of an agent and delete it."""

    pass


class GenericMessage(Message):
    """A generic message that can be used for any type of message."""

    raw: RawMessage = Field(..., description="The raw message.")

    def encode(
        self, content_type: str = "application/json", exclude_defaults: bool = True
    ) -> RawMessage:
        return self.raw

    @classmethod
    def decode(cls, raw: RawMessage) -> Message:
        return cls(reply=raw.reply, extensions=raw.header.extensions, raw=raw)


class Started(Message):
    """A message to notify an agent that it's started."""

    pass


class Stopped(Message):
    """A message to notify an agent that it's stopped."""

    pass


class ProbeAgent(Message):
    """A message to probe the existence of an agent."""

    pass


class SetReplyInfo(Message):
    """A message to set the reply information of an agent.

    This is mainly useful when orchestrating multiple agents to work together.
    """

    reply_info: Reply


class Empty(Message):
    """A message that serves as a placeholder."""

    pass


class StopIteration(Message):
    """A message to notify the end of an iteration."""

    pass


class Error(Message):
    """A message to notify an error."""

    code: str = Field(..., description="Error code")
    message: str = Field(..., description="Error message")

# File: .//coagent/core/exceptions.py
from __future__ import annotations

import json
import traceback

from pydantic import BaseModel, Field
from .messages import Error


class ErrorMeta(type):
    """Metaclass for automatically registering error classes.

    Note that `ErrorMeta` must inherit from `type`, otherwise when defining `BaseError` as below:

    ```python
    class BaseError(Exception, metaclass=ErrorMeta):
    ```

    there will be a metaclass conflict:

    ```
    TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
    ```
    """

    registry = {}

    def __new__(mcls, name, bases, namespace, /, **kwargs):
        cls = super().__new__(mcls, name, bases, namespace, **kwargs)
        mcls.registry[cls.__name__] = cls
        return cls


class RawError(BaseModel):
    code: str = Field(..., description="Error code")
    message: str = Field(..., description="Error message")


class BaseError(Exception, metaclass=ErrorMeta):
    def encode(self, mode: str = "python") -> dict:
        error = RawError(code=self.__class__.__name__, message=str(self))
        return error.model_dump(mode=mode)

    @classmethod
    def decode(cls, data: dict) -> BaseError:
        error = RawError.model_validate(data)
        error_class = cls.registry.get(error.code)
        if not error_class:
            raise ValueError(f"Unknown error code {error.code}")
        return error_class(error.message)

    def encode_json(self) -> str:
        data = self.encode(mode="json")
        return json.dumps(data)

    @classmethod
    def decode_json(cls, json_data: str | bytes) -> BaseError:
        try:
            data = json.loads(json_data)
        except json.JSONDecodeError:
            raise ValueError("Invalid JSON data")
        return cls.decode(data)

    def encode_message(self) -> Error:
        err = self.encode()
        return Error.model_validate(err)

    @classmethod
    def decode_message(cls, msg: Error) -> BaseError:
        err = msg.model_dump()
        return cls.decode(err)


class AgentTypeNotFoundError(BaseError):
    """Raised when the specified agent type in Address is not found."""


class SessionIDEmptyError(BaseError):
    """Raised when the session ID in Address is empty."""


class MessageDecodeError(BaseError):
    """Raised when the message cannot be decoded."""


class InternalError(BaseError):
    """Raised when an internal error occurs."""

    @classmethod
    def from_exception(
        cls, exc: BaseException, with_stack_trace: bool = True
    ) -> InternalError:
        if with_stack_trace:
            exc_info = "".join(traceback.format_exception(exc))
        else:
            exc_info = str(exc)
        return InternalError(exc_info)


class DeadlineExceededError(BaseError):
    """Raised when a context deadline is exceeded."""


class StreamError(BaseError):
    """Raised when the sender requests a non-streaming result but the receiver sends a stream."""

# File: .//coagent/runtimes/local_runtime.py
from __future__ import annotations

import asyncio
import uuid
from typing import Any, AsyncIterator, Awaitable, Callable

import blinker
import pydantic

from coagent.core import (
    Address,
    BaseRuntime,
    BaseChannel,
    QueueSubscriptionIterator,
    RawMessage,
    Reply,
    StopIteration,
    Subscription,
)
from coagent.core.exceptions import (
    AgentTypeNotFoundError,
    BaseError,
    SessionIDEmptyError,
)
from coagent.core.factory import CreateAgent
from coagent.core.messages import Empty, Error
from coagent.core.types import coagent_reply_topic_prefix


class LocalRuntime(BaseRuntime):
    """An in-process runtime."""

    def __init__(self, channel: LocalChannel | None = None):
        channel = channel or LocalChannel()
        super().__init__(channel)


class LocalChannel(BaseChannel):
    """An in-process channel."""

    async def connect(self) -> None:
        pass

    async def close(self) -> None:
        pass

    async def subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]],
        queue: str = "",
    ) -> Subscription:
        return await self._subscribe(addr, handler, queue)

    async def new_reply_topic(self) -> str:
        return f"{coagent_reply_topic_prefix}{uuid.uuid4().hex}"

    async def _subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]] | None = None,
        queue: str = "",
    ) -> LocalChannelSubscription:
        sub = LocalChannelSubscription(addr, handler)
        await sub.subscribe()
        return sub

    async def _publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> RawMessage | None:
        if addr.is_reply or not probe or self._probe(addr):
            return await self._blinker_send(
                addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
            )

        return await self._create_and_publish(
            addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
        )

    async def _create_and_publish(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool = False,
        stream: bool = False,
        reply: str = "",
        timeout: float = 0.5,
    ) -> RawMessage | None:
        if not addr.id:
            raise SessionIDEmptyError(f"Empty ID in addr {addr}")

        # Notify the corresponding factory to create the agent and wait for its reply.
        factory_addr = Address(name=addr.name)
        create_msg = CreateAgent(session_id=addr.id).encode()
        if not self._probe(factory_addr):
            raise AgentTypeNotFoundError(f"No factory found for agent '{addr.name}'")

        await self._blinker_send(factory_addr, create_msg, request=True)

        # Then send the original message to the agent.
        return await self._blinker_send(
            addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
        )

    def _probe(self, addr: Address) -> bool:
        """Probe the existence of the agent at the given address by detecting
        whether there are any receivers for the given topic.

        See https://blinker.readthedocs.io/en/stable/#blinker.Signal.receivers.
        """
        sig = blinker.signal(addr.topic)
        return bool(sig.receivers)

    async def _blinker_send(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool = False,
        stream: bool = False,
        reply: str = "",
        timeout: float = 0.5,
    ) -> RawMessage | None:
        sig = blinker.signal(addr.topic)
        # print(f"[LocalChannel] Sending message {msg} to {addr.topic}, signal: {sig}")

        # TODO: Respect the timeout.

        # **IMPORTANT**:
        # Here we assume that the first argument name of all receivers is "raw".
        # Currently, this aligns with the signature of the `BaseAgent.receive()` method.

        if not request:
            # Not in request-reply mode, just publish the message.
            await sig.send_async(None, raw=msg)
            return None
        elif reply:
            # In request-reply mode and a reply topic is given.
            # Publish the message and the response(s) will be sent to the reply topic.
            msg.reply = Reply(address=Address(name=reply), stream=stream)
            await sig.send_async(None, raw=msg)
            return None
        else:
            # In request-reply mode and no reply topic is given.
            # Wait for a response on a temporary topic and return it.
            tmp_reply = await self.new_reply_topic()
            addr = Address(name=tmp_reply)
            sub = await self._subscribe(addr)

            msg.reply = Reply(address=addr, stream=stream)
            await sig.send_async(None, raw=msg)

            result: RawMessage | None = None
            async for raw in sub.queue:
                result = raw
                break  # Just wait for the first message.

            try:
                Empty.decode(result)
                return None
            except pydantic.ValidationError:
                # Can not be converted to Empty.
                try:
                    err = Error.decode(result)
                    raise BaseError.decode_message(err)
                except pydantic.ValidationError:
                    # Can not be converted to Error, so return the message as is.
                    return result
            finally:
                await sub.unsubscribe()


class LocalChannelSubscription(Subscription):
    def __init__(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]] | None = None,
    ):
        self._addr = addr
        self._handler = handler

        self._queue: QueueSubscriptionIterator = QueueSubscriptionIterator()
        self._task: asyncio.Task | None = None
        self._exit_event: asyncio.Event = asyncio.Event()

    async def subscribe(self):
        sig = blinker.signal(self._addr.topic)
        sig.connect(self._receive, weak=False)

        if self._handler:
            self._task = asyncio.create_task(self._poll())

        # print(f"[LocalChannel] Connecting to {self._addr.topic}, signal: {sig}")

    async def unsubscribe(self, limit: int = 0) -> None:
        sig = blinker.signal(self._addr.topic)
        sig.disconnect(self._receive)

        if self._task:
            self._task.cancel()
            try:
                # This will raise asyncio.CancelledError if the current task was cancelled.
                await self._exit_event.wait()
            except asyncio.CancelledError:
                pass

    @property
    def queue(self) -> AsyncIterator[RawMessage]:
        return self._queue

    async def _receive(self, sender: Any, raw: RawMessage) -> None:
        await self._queue.receive(raw)

    async def _poll(self):
        try:
            async for raw in self._queue:
                await self._handler(raw)

            # End of the stream, send an extra StopIteration message.
            await self._handler(StopIteration().encode())
        except BaseError as exc:
            # Send the error as a message.
            await self._handler(exc.encode_message().encode())
        finally:
            self._exit_event.set()

# File: .//coagent/runtimes/__init__.py
# ruff: noqa: F401
from .http_runtime import HTTPRuntime, HTTPChannelBackend
from .local_runtime import LocalRuntime, LocalChannel
from .nats_runtime import NATSRuntime, NATSChannel

# File: .//coagent/runtimes/nats_runtime.py
from __future__ import annotations

import asyncio
import json
from typing import List, Union, Callable, Awaitable

import nats
from nats.aio.client import Msg
from nats.aio.subscription import Subscription as NATSSubscription
from nats.errors import ConnectionClosedError, NoRespondersError, TimeoutError
import pydantic

from coagent.core import (
    Address,
    BaseRuntime,
    BaseChannel,
    MessageHeader,
    RawMessage,
    Reply,
    Subscription,
)
from coagent.core.exceptions import (
    AgentTypeNotFoundError,
    BaseError,
    DeadlineExceededError,
    SessionIDEmptyError,
)
from coagent.core.messages import ProbeAgent, Empty, Error
from coagent.core.factory import CreateAgent


class NATSRuntime(BaseRuntime):
    """A NATS-based runtime."""

    def __init__(self, channel: NATSChannel):
        super().__init__(channel)

    @classmethod
    def from_servers(cls, servers: Union[str, List[str], None] = None) -> NATSRuntime:
        channel = NATSChannel(servers)
        return NATSRuntime(channel)


class NATSChannel(BaseChannel):
    """A NATS-based channel."""

    def __init__(self, servers: Union[str, List[str], None] = None):
        self._servers: Union[str, List[str]] = servers or ["nats://localhost:4222"]
        self._nc: nats.NATS | None = None

    async def connect(self) -> None:
        self._nc = await nats.connect(self._servers)

    async def close(self) -> None:
        try:
            await self._nc.drain()
        except ConnectionClosedError:
            pass

    async def subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]],
        queue: str = "",
    ) -> Subscription:
        async def receive(msg: Msg) -> None:
            raw = nats_msg_to_raw(msg)
            await handler(raw)

        sub = await self._nc.subscribe(addr.topic, queue=queue, cb=receive)
        return NATSChannelSubscription(sub)

    async def new_reply_topic(self) -> str:
        return self._nc.new_inbox()

    async def _publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 0.5,
        probe: bool = True,
    ) -> RawMessage | None:
        if addr.is_reply or not probe or await self._probe(addr):
            return await self._nats_publish(
                addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
            )

        if request:
            # If in request-reply (or non-blocking) mode, always wait for the reply.
            return await self._create_and_publish(
                addr,
                msg,
                request=request,
                stream=stream,
                reply=reply,
                timeout=timeout,
            )

        # Run in a separate task to avoid blocking the agent handler.
        _ = asyncio.create_task(
            self._create_and_publish(
                addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
            )
        )

    async def _create_and_publish(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool = False,
        stream: bool = False,
        reply: str = "",
        timeout: float = 0.5,
    ) -> RawMessage | None:
        if not addr.id:
            raise SessionIDEmptyError(f"Empty ID in addr {addr}")

        # Notify the corresponding factory to create the agent and wait for its reply.
        factory_addr = Address(name=addr.name)
        create_msg = CreateAgent(session_id=addr.id).encode()
        try:
            # Wait at most 5 seconds for the factory to create an agent.
            await self._nats_publish(factory_addr, create_msg, request=True, timeout=5)
        except NoRespondersError:
            raise AgentTypeNotFoundError(f"No factory found for agent '{addr.name}'")
        except TimeoutError:
            raise DeadlineExceededError(
                f"Factory {factory_addr.name} is too slow to respond"
            )

        # Then send the original message to the agent.
        return await self._nats_publish(
            addr, msg, request=request, stream=stream, reply=reply, timeout=timeout
        )

    async def _probe(self, addr: Address) -> bool:
        """Probe the existence of the agent at the given address by leveraging
        the `No responders` mechanism of NATS to check if there are available
        subscribers for the given topic.

        See https://docs.nats.io/nats-concepts/core-nats/reqreply#no-responders.

        Note that this might not be the best way since it will introduce a small
        delay to each publish operation.
        """
        try:
            await self._nats_publish(
                addr, ProbeAgent().encode(), request=True, timeout=0.01
            )  # 10ms
        except NoRespondersError:
            return False
        except Exception:
            return True
        else:
            return True

    async def _nats_publish(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool = False,
        stream: bool = False,
        reply: str = "",
        timeout: float = 0.5,
    ) -> RawMessage | None:
        topic = addr.topic
        headers = {
            "Coagent-Type": msg.header.type,
            "Coagent-Content-Type": msg.header.content_type,
            "Coagent-Extensions": json.dumps(msg.header.extensions),
            "Coagent-Stream": "true" if stream else "false",
        }
        payload = msg.content

        if not request:
            # Not in request-reply mode, just publish the message.
            return await self._nc.publish(topic, payload, headers=headers)
        elif reply:
            # In request-reply mode and a reply topic is given.
            # Publish the message and the response(s) will be sent to the reply topic.
            return await self._nc.publish(topic, payload, reply=reply, headers=headers)
        else:
            # In request-reply mode and no reply topic is given.
            # Publish the message and wait for a response on a temporary topic.
            result = await self._nc.request(
                topic, payload, timeout=timeout, headers=headers
            )
            result_msg = nats_msg_to_raw(result)
            try:
                Empty.decode(result_msg)
                return None
            except pydantic.ValidationError:
                # Can not be converted to Empty.
                try:
                    err = Error.decode(result_msg)
                    raise BaseError.decode_message(err)
                except pydantic.ValidationError:
                    # Can not be converted to Error, so return the message as is.
                    return result_msg


class NATSChannelSubscription(Subscription):
    def __init__(self, sub: NATSSubscription):
        self._sub: NATSSubscription = sub

    async def unsubscribe(self, limit: int = 0) -> None:
        try:
            await self._sub.unsubscribe(limit)
        except ConnectionClosedError:
            pass


def nats_msg_to_raw(msg: Msg) -> RawMessage:
    header = MessageHeader(
        type=msg.header.get("Coagent-Type"),
        content_type=msg.header.get("Coagent-Content-Type"),
        extensions=json.loads(msg.header.get("Coagent-Extensions", "{}")),
    )
    raw = RawMessage(
        header=header,
        content=msg.data,
    )
    if msg.reply:
        stream = msg.header.get("Coagent-Stream") == "true"
        raw.reply = Reply(address=Address(name=msg.reply), stream=stream)
    return raw

# File: .//coagent/runtimes/http_runtime.py
from __future__ import annotations

import asyncio
from typing import AsyncIterator, Awaitable, Callable

import httpx
from httpx_sse import aconnect_sse

from coagent.core import (
    Address,
    BaseRuntime,
    BaseChannel,
    Channel,
    logger,
    RawMessage,
    QueueSubscriptionIterator,
    StopIteration,
    Subscription,
)
from coagent.core.exceptions import BaseError


http2_client = httpx.AsyncClient(http2=True)


class HTTPRuntime(BaseRuntime):
    """An HTTP-based runtime."""

    def __init__(self, channel: HTTPChannel):
        super().__init__(channel)

    @classmethod
    def from_server(cls, server: str, auth: str = "") -> HTTPRuntime:
        """
        Args:
            server (str): The server address.
            auth (str, optional): The authentication credential. Defaults to "".
        """
        channel = HTTPChannel(server, auth)
        return HTTPRuntime(channel)


class HTTPChannel(BaseChannel):
    """An HTTP-based channel.

    _publish: POST /publish
    _publish_stream: POST /publish stream=True
    subscribe: POST /subscribe
    new_reply_topic: POST /reply-topics
    """

    def __init__(self, server: str, auth: str = ""):
        """
        Args:
            server (str): The server address.
            auth (str, optional): The authentication credential. Defaults to "".
        """
        self._server: str = server
        self._auth: str = auth

    async def connect(self) -> None:
        pass

    async def close(self) -> None:
        pass

    async def _publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 5.0,
        probe: bool = True,
    ) -> RawMessage | None:
        data = dict(
            addr=addr.encode(mode="json"),
            msg=msg.encode(mode="json"),
            stream=stream,
            request=request,
            reply=reply,
            timeout=timeout,
            probe=probe,
        )
        headers = {"Authorization": self._auth} if self._auth else None

        resp = await http2_client.post(
            f"{self._server}/publish", json=data, headers=headers, timeout=timeout
        )

        if resp.status_code == 200:
            return RawMessage.model_validate_json(resp.content)

        if resp.is_error:
            raise_http_error(resp, resp.text)

    async def _publish_stream(
        self,
        addr: Address,
        msg: RawMessage,
        probe: bool = True,
    ) -> AsyncIterator[RawMessage]:
        """
        Note that we do not use the default implementation from BaseChannel,
        because multiple HTTP calls will result in poor performance.
        """
        data = dict(
            addr=addr.encode(mode="json"),
            msg=msg.encode(mode="json"),
            stream=True,
            request=True,
            probe=probe,
        )
        headers = {"Authorization": self._auth} if self._auth else None

        queue: QueueSubscriptionIterator = QueueSubscriptionIterator()
        sub: HTTPChannelSubscription = HTTPChannelSubscription(
            f"{self._server}/publish", data, headers, queue.receive
        )
        await sub.subscribe()

        try:
            async for msg in queue:
                yield msg
        finally:
            await sub.unsubscribe()

    async def subscribe(
        self,
        addr: Address,
        handler: Callable[[RawMessage], Awaitable[None]],
        queue: str = "",
    ) -> Subscription:
        data = dict(
            addr=addr.encode(mode="json"),
            queue=queue,
        )
        headers = {"Authorization": self._auth} if self._auth else None

        sub = HTTPChannelSubscription(
            f"{self._server}/subscribe", data, headers, handler
        )
        await sub.subscribe()
        return sub

    async def new_reply_topic(self) -> str:
        data = dict()
        headers = {"Authorization": self._auth} if self._auth else None

        async with httpx.AsyncClient() as client:
            resp = await client.post(
                f"{self._server}/reply-topics", json=data, headers=headers
            )
            result = resp.json()
            return result["reply_topic"]


class HTTPChannelSubscription(Subscription):
    """A subscription created when subscribing to an HTTP-based channel."""

    def __init__(
        self,
        url: str,
        data: dict,
        headers: dict | None,
        handler: Callable[[RawMessage], Awaitable[None]],
    ):
        self._url: str = url
        self._data: dict = data
        self._headers: dict | None = headers
        self._handler: Callable[[RawMessage], Awaitable[None]] = handler

        self._task: asyncio.Task = asyncio.create_task(self._poll())
        self._subscribe_event: asyncio.Event = asyncio.Event()
        self._exit_event: asyncio.Event = asyncio.Event()

    async def subscribe(self):
        # Wait until the subscription is created.
        await self._subscribe_event.wait()

    async def unsubscribe(self, limit: int = 0) -> None:
        """Align to NATS for simplicity."""
        self._task.cancel()
        try:
            # This will raise asyncio.CancelledError if the current task was cancelled.
            await self._exit_event.wait()
        except asyncio.CancelledError:
            pass

    async def _poll(self) -> None:
        while True:
            async with httpx.AsyncClient(timeout=None) as client:
                try:
                    async with aconnect_sse(
                        client,
                        "POST",
                        self._url,
                        json=self._data,
                        headers=self._headers or {},
                    ) as event_source:
                        if not self._subscribe_event.is_set():
                            # Notify that the subscription is created.
                            self._subscribe_event.set()

                        async for sse in event_source.aiter_sse():
                            data_str = sse.data

                            # There's no standard way to send errors in SSE (https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events).
                            # Here we assume that if the event is "error", an error has occurred on the server side.
                            #
                            # For error handling on the SSE server side, see `publish_multi()`
                            # in examples/ping-pong/http_runtime_server.py
                            if sse.event == "error":
                                raise_http_error(event_source.response, data_str)

                            raw: RawMessage = RawMessage.model_validate_json(data_str)
                            await self._handler(raw)

                        # End of the stream, send an extra StopIteration message.
                        await self._handler(StopIteration().encode())
                        # Exit the loop.
                        self._exit_event.set()
                        break
                # except (BaseError, httpx.HTTPStatusError) as exc:
                except BaseError as exc:
                    # Send the error as a message.
                    await self._handler(exc.encode_message().encode())
                    break
                except asyncio.CancelledError:
                    # User cancelled, close the client and exit.
                    await client.aclose()
                    # TODO: We use break here since using raise doesn't work as expected.
                    break
                except Exception as exc:
                    # Other errors, reconnect in 3 seconds
                    logger.exception(f"Error occurred: {type(exc)}, {exc}")
                    await asyncio.sleep(3)

        self._exit_event.set()


def raise_http_error(resp: httpx.Response, error_str: str | bytes):
    try:
        exc = BaseError.decode_json(error_str)
        raise exc
    except ValueError:
        raise httpx.HTTPStatusError(error_str, request=resp.request, response=resp)


class HTTPChannelBackend:
    """A backend for the HTTP-based channel.

    This helper backend is typically used in conjunction with Starlette or
    FastAPI on the server side.

    See examples/ping-pong/http_runtime_server.py for a reference server implementation.
    """

    def __init__(self, channel: Channel):
        self._channel: Channel = channel

    async def start(self):
        await self._channel.connect()

    async def stop(self):
        await self._channel.close()

    async def publish(
        self,
        addr: Address,
        msg: RawMessage,
        stream: bool = False,
        request: bool = False,
        reply: str = "",
        timeout: float = 5.0,
        probe: bool = True,
    ) -> AsyncIterator[RawMessage] | RawMessage | None:
        return await self._channel.publish(
            addr,
            msg,
            stream=stream,
            request=request,
            reply=reply,
            timeout=timeout,
            probe=probe,
        )

    async def subscribe(
        self,
        addr: Address,
        queue: str = "",
    ) -> AsyncIterator[RawMessage]:
        msg_queue: QueueSubscriptionIterator = QueueSubscriptionIterator()

        sub = await self._channel.subscribe(
            addr, handler=msg_queue.receive, queue=queue
        )

        try:
            async for msg in msg_queue:
                yield msg
        finally:
            await sub.unsubscribe()

    async def new_reply_topic(self) -> str:
        return await self._channel.new_reply_topic()

# File: .//coagent/agents/dynamic_triage.py
import re
from typing import AsyncIterator

from coagent.core import (
    Address,
    BaseAgent,
    Context,
    DiscoveryQuery,
    DiscoveryReply,
    handler,
    logger,
    Message,
    RawMessage,
)
from coagent.core.discovery import (
    AgentsRegistered,
    AgentsDeregistered,
    Schema,
    SubscribeToAgentUpdates,
    UnsubscribeFromAgentUpdates,
)

from .aswarm import Agent as SwarmAgent, Swarm
from .chat_agent import ChatHistory, ChatMessage, Delegate
from .model_client import default_model_client, ModelClient


class UpdateSubAgents(Message):
    agents: list[Schema]


class DynamicTriage(BaseAgent):
    """A triage agent that dynamically discovers its sub-agents and delegates conversation to these sub-agents."""

    def __init__(
        self,
        name: str = "",
        system: str = "",
        namespace: str = "",
        inclusive: bool = False,
        client: ModelClient = default_model_client,
    ):
        super().__init__()

        self._name: str = name
        self._system: str = system
        self._namespace: str = namespace
        self._inclusive: bool = inclusive
        self._client: ModelClient = client

        self._swarm_client = Swarm(self.client)

        self._sub_agents: dict[str, Schema] = {}
        self._swarm_agent: SwarmAgent | None = None

        self._history: ChatHistory = ChatHistory(messages=[])

    @property
    def name(self) -> str:
        if self._name:
            return self._name

        n = self.__class__.__name__
        return re.sub("([a-z0-9])([A-Z])", r"\1_\2", n).lower()

    @property
    def system(self) -> str:
        """The system instruction for this agent."""
        return self._system

    @property
    def namespace(self) -> str:
        """The namespace for this agent."""
        return self._namespace

    @property
    def inclusive(self) -> bool:
        """Whether to include the agent whose name equals to the namespace."""
        return self._inclusive

    @property
    def client(self) -> ModelClient:
        return self._client

    async def _update_swarm_agent(self) -> None:
        agent_names = list(self._sub_agents.keys())
        logger.debug(
            f"[{self.__class__.__name__} {self.id}] Discovered sub-agents: {agent_names}"
        )

        tools = []
        for agent in self._sub_agents.values():
            transfer_to = self._transfer_to_agent(agent.name)
            transfer_to.__name__ = f"transfer_to_{agent.name.replace('.', '_')}"
            transfer_to.__doc__ = agent.description
            tools.append(transfer_to)

        self._swarm_agent = SwarmAgent(
            name=self.name,
            model=self.client.model,
            instructions=self.system,
            functions=tools,
        )

    def _transfer_to_agent(self, agent_type: str):
        async def run() -> AsyncIterator[ChatMessage]:
            async for chunk in Delegate(self, agent_type).handle(self._history):
                yield chunk

        return run

    async def start(self) -> None:
        await super().start()

        query = DiscoveryQuery(
            namespace=self.namespace,
            inclusive=self.inclusive,
        )
        msg = SubscribeToAgentUpdates(sender=self.address, query=query)
        await self.channel.publish(Address(name="discovery"), msg.encode(), probe=False)

        # To make the newly-created triage agent immediately available,
        # we must query its sub-agents once in advance.
        result: RawMessage = await self.channel.publish(
            Address(name="discovery"),
            query.encode(),
            request=True,
            probe=False,
        )
        reply: DiscoveryReply = DiscoveryReply.decode(result)

        self._sub_agents = {agent.name: agent for agent in reply.agents}
        await self._update_swarm_agent()

    async def stop(self) -> None:
        msg = UnsubscribeFromAgentUpdates(sender=self.address)
        await self.channel.publish(Address(name="discovery"), msg.encode(), probe=False)

        await super().stop()

    @handler
    async def register_sub_agents(self, msg: AgentsRegistered, ctx: Context) -> None:
        for agent in msg.agents:
            self._sub_agents[agent.name] = agent
        await self._update_swarm_agent()

    @handler
    async def deregister_sub_agents(
        self, msg: AgentsDeregistered, ctx: Context
    ) -> None:
        for agent in msg.agents:
            self._sub_agents.pop(agent.name, None)
        await self._update_swarm_agent()

    @handler
    async def handle_history(
        self, msg: ChatHistory, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        response = self._handle_history(msg, ctx)
        async for resp in response:
            yield resp

    @handler
    async def handle_message(
        self, msg: ChatMessage, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        history = ChatHistory(messages=[msg])
        response = self._handle_history(history, ctx)
        async for resp in response:
            yield resp

    async def _handle_history(
        self, msg: ChatHistory, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        # For now, we assume that the agent is processing messages sequentially.
        self._history: ChatHistory = msg

        response = self._swarm_client.run_and_stream(
            agent=self._swarm_agent,
            messages=[m.model_dump() for m in msg.messages],
            context_variables=msg.extensions,
        )
        async for resp in response:
            if isinstance(resp, ChatMessage) and resp.content:
                yield resp

# File: .//coagent/agents/mcp_agent.py
import dataclasses
from typing import Any, AsyncContextManager, Callable
from urllib.parse import urljoin

from coagent.core.exceptions import InternalError
from mcp import ClientSession, Tool, McpError
from mcp.types import ImageContent, TextContent
from mcp.client.sse import sse_client
from mcp.client.stdio import stdio_client, StdioServerParameters
import jsonschema

from .aswarm import Agent as SwarmAgent
from .chat_agent import ChatAgent, wrap_error
from .model_client import default_model_client, ModelClient


@dataclasses.dataclass
class Prompt:
    name: str
    arguments: dict[str, str] | None = None


class MCPAgent(ChatAgent):
    """An agent that can use tools provided by MCP (Model Context Protocol) servers."""

    def __init__(
        self,
        system: Prompt | None = None,
        mcp_server_base_url: str = "",
        client: ModelClient = default_model_client,
    ) -> None:
        super().__init__(system="", client=client)

        self._mcp_server_base_url: str = mcp_server_base_url
        self._mcp_client_transport: AsyncContextManager[tuple] | None = None
        self._mcp_client_session: ClientSession | None = None

        self._mcp_swarm_agent: SwarmAgent | None = None
        self._mcp_system_prompt_config: Prompt | None = system

    @property
    def mcp_server_base_url(self) -> str:
        if not self._mcp_server_base_url:
            raise ValueError("MCP server base URL is empty")
        return self._mcp_server_base_url

    def _make_mcp_client_transport(self) -> AsyncContextManager[tuple]:
        if self.mcp_server_base_url.startswith(("http://", "https://")):
            url = urljoin(self.mcp_server_base_url, "sse")
            return sse_client(url=url)
        else:
            # Mainly for testing purposes.
            command, arg = self.mcp_server_base_url.split(" ", 1)
            params = StdioServerParameters(command=command, args=[arg])
            return stdio_client(params)

    async def started(self) -> None:
        """
        Combining `started` and `stopped` to achieve the following behavior:

            async with sse_client(url=url) as (read, write):
                async with ClientSession(read, write) as session:
                    pass
        """
        self._mcp_client_transport = self._make_mcp_client_transport()
        read, write = await self._mcp_client_transport.__aenter__()

        self._mcp_client_session = ClientSession(read, write)
        await self._mcp_client_session.__aenter__()

        # Initialize the connection
        await self._mcp_client_session.initialize()

    async def stopped(self) -> None:
        await self._mcp_client_session.__aexit__(None, None, None)
        await self._mcp_client_transport.__aexit__(None, None, None)

    async def _handle_data(self) -> None:
        """Override the method to handle exceptions properly."""
        try:
            await super()._handle_data()
        finally:
            # Ensure the resources created in `started` are properly cleaned up.
            await self.stopped()

    async def get_swarm_agent(self) -> SwarmAgent:
        if not self._mcp_swarm_agent:
            system = await self._get_prompt(self._mcp_system_prompt_config)
            tools = await self._get_tools()
            self._mcp_swarm_agent = SwarmAgent(
                name=self.name,
                model=self.client.model,
                instructions=system,
                functions=[wrap_error(t) for t in tools],
            )
        return self._mcp_swarm_agent

    async def _get_prompt(self, prompt_config: Prompt | None) -> str:
        if not prompt_config:
            return ""

        try:
            prompt = await self._mcp_client_session.get_prompt(
                **dataclasses.asdict(prompt_config),
            )
        except McpError as exc:
            raise InternalError(str(exc))

        content = prompt.messages[0].content
        match content:
            case TextContent():
                return content.text
            case _:  # ImageContent() or EmbeddedResource() or other types
                return ""

    async def _get_tools(self) -> list[Callable]:
        result = await self._mcp_client_session.list_tools()
        tools = [self._make_tool(t) for t in result.tools]
        return tools

    def _make_tool(self, t: Tool) -> Callable:
        async def tool(**kwargs) -> Any:
            # Validate the input against the schema
            jsonschema.validate(instance=kwargs, schema=t.inputSchema)
            # Actually call the tool.
            result = await self._mcp_client_session.call_tool(t.name, arguments=kwargs)
            if not result.content:
                return ""
            content = result.content[0]

            if result.isError:
                raise ValueError(content.text)

            match content:
                case TextContent():
                    return content.text
                case ImageContent():
                    return content.data
                case _:  # EmbeddedResource() or other types
                    return ""

        tool.__name__ = t.name
        tool.__doc__ = t.description

        # Attach the schema and arguments to the tool.
        tool.__mcp_tool_schema__ = dict(
            name=t.name,
            description=t.description,
            parameters=t.inputSchema,
        )
        tool.__mcp_tool_args__ = tuple(t.inputSchema["properties"].keys())
        return tool

# File: .//coagent/agents/structured_agent.py
from typing import AsyncIterator, Callable, Type

from coagent.core import Context, GenericMessage, handler, Message
from jinja2 import Template
from pydantic import BaseModel

from .chat_agent import ChatAgent
from .messages import ChatHistory, ChatMessage, type_to_response_format_param
from .model_client import default_model_client, ModelClient


class StructuredAgent(ChatAgent):
    def __init__(
        self,
        input_type: Type[Message],
        output_type: Type[BaseModel] | Type[str] = str,
        system: str = "",
        messages: list[ChatMessage] | None = None,
        tools: list[Callable] | None = None,
        client: ModelClient = default_model_client,
    ):
        super().__init__(system=system, tools=tools, client=client)
        self._input_type: Type[Message] = input_type
        self._output_type: Type[BaseModel] | Type[str] = output_type

        self.__messages: list[ChatMessage] | None = messages

    async def render_system(self, _input: Message) -> str:
        """Render the system prompt.

        This is a default implementation that renders the system prompt using Jinja2.
        Override this method to implement custom rendering logic.
        """
        if not self._system:
            return ""
        return Template(self._system).render(_input.model_dump())

    async def render_messages(self, _input: Message) -> list[ChatMessage]:
        """Render the chat messages.

        This is a default implementation that renders the chat messages using Jinja2.
        Override this method to implement custom rendering logic.
        """
        if self.__messages:
            data = _input.model_dump()
            return [
                ChatMessage(role=m.role, content=Template(m.content).render(data))
                for m in self.__messages
            ]

        # No initial messages are provided.
        # Build the chat messages based on the input message.
        match _input:
            case ChatMessage():
                return [_input]
            case ChatHistory():
                return _input.messages
            case _:
                return [ChatMessage(role="user", content=_input.model_dump_json())]

    @handler
    async def handle(
        self, msg: GenericMessage, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        _input = self._input_type.decode(msg.raw)

        # This is a hack to make the system prompt dynamic.
        self._swarm_agent.instructions = await self.render_system(_input)
        messages = await self.render_messages(_input)

        history = ChatHistory(messages=messages)
        output_schema: dict | None = None
        if self._output_type is not str:
            output_schema = type_to_response_format_param(self._output_type)

        response = self._handle_history(history, output_schema)
        async for resp in response:
            yield resp

# File: .//coagent/agents/util.py
import asyncio
import functools
from typing import AsyncIterator

from coagent.core import logger

from .messages import ChatMessage
from .model_client import default_model_client, ModelClient


async def chat(
    messages: list[ChatMessage],
    stream: bool = False,
    client: ModelClient = default_model_client,
) -> AsyncIterator[ChatMessage] | ChatMessage:
    if stream:
        return _chat_stream(messages, client)

    response = await client.acompletion(
        messages=[m.model_dump() for m in messages],
    )
    msg = response.choices[0].message
    return ChatMessage(
        role=msg.role,
        content=msg.content,
    )


async def _chat_stream(
    messages: list[ChatMessage], client: ModelClient = default_model_client
) -> AsyncIterator[ChatMessage]:
    response = await client.acompletion(
        messages=[m.model_dump() for m in messages],
        stream=True,
    )
    async for chunk in response:
        msg = chunk.choices[0].delta
        if msg.content:
            yield ChatMessage(role="assistant", content=msg.content)


def run_in_thread(func):
    @functools.wraps(func)
    async def run(*args, **kwargs):
        return await asyncio.to_thread(func, *args, **kwargs)

    return run


async def is_user_confirmed(
    content: str, client: ModelClient = default_model_client
) -> bool:
    """Check whether the user has confirmed or not based on the content."""
    # Quick path
    if content.lower() in ("yes", "ok", "1"):
        return True
    elif content.lower() in ("no", "do not", "0"):
        return False

    logger.debug(f"Using {client.model} to analyze the user's sentiment")

    reply = await chat(
        [
            ChatMessage(
                role="user",
                content=f"""\
Based on the input, determine whether it's positive or not. Return "true" if it's
positive or "false" if not. You should only return "true" or "false.

Input: {content}
Output:\
""",
            )
        ],
        client=client,
    )
    answer = reply.content
    return answer.strip().lower() == "true"

# File: .//coagent/agents/model_client.py
import os

# Importing litellm is super slow, so we are using lazy import for now.
# See https://github.com/BerriAI/litellm/issues/7605.
#
# import litellm
from pydantic import BaseModel, Field


# class ModelResponse(litellm.ModelResponse):
#     pass


class ModelClient(BaseModel):
    provider: str = Field("", description="The model provider.")
    model: str = Field(..., description="The model name.")
    api_base: str = Field("", description="The API base URL.")
    api_version: str = Field("", description="The API version.")
    api_key: str = Field("", description="The API key.")

    @property
    def llm_provider(self) -> str:
        if self.provider:
            return self.provider

        import litellm

        _, provider, _, _ = litellm.get_llm_provider(
            self.model,
            api_base=self.api_base or None,
        )
        return provider

    async def acompletion(
        self,
        messages: list[dict],
        model: str = "",
        stream: bool = False,
        temperature: float = 0.1,
        tools: list | None = None,
        tool_choice: str | None = None,
        response_format: dict | None = None,
        **kwargs,
    ):  # -> ModelResponse:
        import litellm

        model = model or self.model
        response = await litellm.acompletion(
            model=model,
            messages=messages,
            stream=stream,
            temperature=temperature,
            tools=tools,
            tool_choice=tool_choice,
            api_base=self.api_base,
            api_version=self.api_version,
            api_key=self.api_key,
            response_format=response_format,
            **kwargs,
        )
        return response


default_model_client = ModelClient(
    model=os.getenv("AZURE_MODEL", ""),
    api_base=os.getenv("AZURE_API_BASE", ""),
    api_version=os.getenv("AZURE_API_VERSION", ""),
    api_key=os.getenv("AZURE_API_KEY", ""),
)

# File: .//coagent/agents/__init__.py
# ruff: noqa: F401
from .chat_agent import ChatAgent, confirm, submit, RunContext, tool
from .dynamic_triage import DynamicTriage
from .mcp_agent import MCPAgent
from .messages import (
    ChatHistory,
    ChatMessage,
    StructuredOutput,
    type_to_response_format_param,
)
from .model_client import ModelClient
from .parallel import Aggregator, AggregationResult, Parallel
from .sequential import Sequential

# File: .//coagent/agents/sequential.py
from coagent.core import (
    Address,
    BaseAgent,
    Context,
    GenericMessage,
    NO_REPLY,
    Reply,
    SetReplyInfo,
    handler,
)


class Sequential(BaseAgent):
    """Sequential is a composite agent that orchestrates its children sequentially."""

    def __init__(self, *agent_types: str):
        super().__init__()
        self._agent_types = agent_types

    async def started(self) -> None:
        for i in range(len(self._agent_types) - 1):
            # Set the reply address of the current agent to be the next agent.
            addr = Address(name=self._agent_types[i], id=self.address.id)
            next_addr = Address(name=self._agent_types[i + 1], id=self.address.id)
            reply = Reply(address=next_addr)
            await self.channel.publish(
                addr,
                SetReplyInfo(reply_info=reply).encode(),
            )

        # Set the current agent to no-reply mode.
        await self._set_reply_info(NO_REPLY)

    @handler
    async def handle(self, msg: GenericMessage, ctx: Context) -> None:
        if len(self._agent_types) == 0:
            raise RuntimeError("No agent types provided.")

        # Let the last agent reply to the sending agent, if asked.
        reply = msg.reply
        if reply:
            last_addr = Address(name=self._agent_types[-1], id=self.address.id)
            await self.channel.publish(
                last_addr,
                SetReplyInfo(reply_info=reply).encode(),
            )

        # Send the message to the first agent in the list.
        addr = Address(name=self._agent_types[0], id=self.address.id)
        await self.channel.publish(addr, msg.encode())

# File: .//coagent/agents/messages.py
from __future__ import annotations

from typing import Any, Type

from coagent.core import logger, Message
from pydantic import BaseModel, Field, field_validator, field_serializer


class ChatMessage(Message):
    role: str = Field(
        ..., description="The role of the message. (e.g. `user`, `assistant`)"
    )
    content: str = Field(
        default="",
        description="The content of the message. For reasoning models, this is the content of the final answer.",
    )
    reasoning_content: str = Field(
        default="",
        description="The content of the CoT. Only available for reasoning models.",
    )

    type: str = Field(default="", description="The type of the message. e.g. confirm")
    sender: str = Field(default="", description="The sending agent of the message.")
    to_user: bool = Field(
        default=False, description="Whether the message is sent directly to user."
    )

    def __add__(self, other: ChatMessage) -> ChatMessage:
        self.content += other.content
        self.reasoning_content += other.reasoning_content
        return self

    @property
    def has_content(self) -> bool:
        return bool(self.content or self.reasoning_content)

    def model_dump(self, **kwargs) -> dict[str, Any]:
        return super().model_dump(include={"role", "content"}, **kwargs)

    def to_llm_message(self) -> dict[str, Any]:
        return super().model_dump(include={"role", "content"})


class ChatHistory(Message):
    messages: list[ChatMessage]


class StructuredOutput(Message):
    input: ChatMessage | ChatHistory = Field(..., description="Input message.")
    output_type: Type[BaseModel] | None = Field(
        None,
        description="Output schema specified as a Pydantic model. Equivalent to OpenAI's `response_format`.",
    )
    output_schema: dict | None = Field(
        None,
        description="Output schema specified as a dict. Setting this suppresses `output_type`.",
    )

    @field_serializer("input")
    def serialize_input(self, value: Message, _info) -> dict:
        data = value.model_dump(exclude_defaults=True)
        data["__message_type__"] = value.__class__.__name__
        return data

    @field_validator("input", mode="before")
    @classmethod
    def validate_input(cls, value: Message | dict) -> Message:
        if isinstance(value, dict):
            message_type = value.pop("__message_type__", None)
            match message_type:
                # Only support ChatMessage and ChatHistory for now.
                case "ChatMessage":
                    return ChatMessage.model_validate(value)
                case "ChatHistory":
                    return ChatHistory.model_validate(value)
        return value

    @field_serializer("output_type")
    def serialize_output_type(self, value: Type[BaseModel] | None, _info) -> None:
        # Always return None for `output_type` since it will be converted to `output_schema`.
        return None

    @field_serializer("output_schema")
    def serialize_output_schema(self, value: dict | None, _info) -> dict | None:
        if self.output_type:
            if value:
                logger.warning("Setting output_schema suppresses output_type")
                return value
            return type_to_response_format_param(self.output_type)

        return value


def type_to_response_format_param(
    response_format: Type[BaseModel] | dict | None,
) -> dict | None:
    import litellm.utils

    return litellm.utils.type_to_response_format_param(response_format)

# File: .//coagent/agents/parallel.py
from typing import Awaitable, Callable
from coagent.core import (
    Address,
    BaseAgent,
    Context,
    handler,
    GenericMessage,
    Message,
    NO_REPLY,
    RawMessage,
    Reply,
    SetReplyInfo,
)


class StartAggregation(Message):
    candidates: list[str]
    reply_info: Reply | None


class AggregationStatus(Message):
    status: str

    @property
    def busy(self) -> bool:
        return self.status == "busy"


class AggregationResult(Message):
    results: list[RawMessage]


class Aggregator(BaseAgent):
    def __init__(
        self,
        aggregate: Callable[[list[RawMessage]], Awaitable[RawMessage]] | None = None,
    ):
        super().__init__()

        self._aggregate = aggregate or self.aggregate

        self._busy: bool = False
        self._data: StartAggregation | None = None
        self._results: list[RawMessage] | None = None

    @handler
    async def start_aggregation(
        self, msg: StartAggregation, ctx: Context
    ) -> AggregationStatus:
        if self._busy:
            return AggregationStatus(status="busy")

        self._busy = True
        self._data = msg
        self._results = []

        return AggregationStatus(status="ok")

    @handler
    async def handle(self, msg: GenericMessage, ctx: Context) -> None:
        if not self._busy:
            return

        self._results.append(msg.encode())

        if len(self._results) == len(self._data.candidates):
            if self._data.reply_info:
                result = await self._aggregate(self._results)
                await self.send_reply(self._data.reply_info, result)
            self._busy = False

    async def aggregate(self, results: list[RawMessage]) -> Message:
        """Aggregate the results to a single one.

        Override this method to provide custom aggregation logic.
        """
        return AggregationResult(results=results)


class Parallel(BaseAgent):
    """Parallel is a composite agent that orchestrates its children agents
    concurrently and have their outputs aggregated by the given aggregator agent.
    """

    def __init__(self, *agent_types: str, aggregator: str = ""):
        super().__init__()
        self._agent_types = agent_types
        self._aggregator_type = aggregator

    async def started(self) -> None:
        aggregator_addr = Address(name=self._aggregator_type, id=self.address.id)
        aggregator_reply = Reply(address=aggregator_addr)
        # Make each agent reply to the aggregator agent.
        for agent_type in self._agent_types:
            addr = Address(name=agent_type, id=self.address.id)
            await self.channel.publish(
                addr,
                SetReplyInfo(reply_info=aggregator_reply).encode(),
            )

        # Set the current agent to no-reply mode.
        await self._set_reply_info(NO_REPLY)

    @handler
    async def handle(self, msg: GenericMessage, ctx: Context) -> None:
        if len(self._agent_types) == 0:
            raise RuntimeError("No agent types provided.")

        # Let the aggregator agent reply to the sending agent, if asked.
        reply = msg.reply
        result = await self.channel.publish(
            Address(name=self._aggregator_type, id=self.address.id),
            StartAggregation(candidates=self._agent_types, reply_info=reply).encode(),
            request=True,
        )
        status = AggregationStatus.decode(result)
        if status.busy:
            # The aggregator agent is busy.
            raise RuntimeError("Parallel agent is busy.")

        for agent_type in self._agent_types:
            addr = Address(name=agent_type, id=self.address.id)
            await self.channel.publish(addr, msg.encode())

# File: .//coagent/agents/aswarm/util.py
import inspect
from datetime import datetime
from typing import Any

from pydantic import Field, create_model
from pydantic.fields import FieldInfo

from coagent.agents.messages import ChatMessage

__CTX_VARS_NAME__ = "ctx"


def debug_print(debug: bool, *args: str) -> None:
    if not debug:
        return
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    message = " ".join(map(str, args))
    print(f"\033[97m[\033[90m{timestamp}\033[97m]\033[90m {message}\033[0m")


def merge_fields(target, source):
    for key, value in source.items():
        if isinstance(value, str):
            # A dirty workaround to avoid containing duplicate "function" in
            # the `type` field. (e.g. "functionfunction")
            if key == "type" and target[key] == "function":
                continue
            target[key] += value
        elif value is not None and isinstance(value, dict):
            merge_fields(target[key], value)


def merge_chunk(final_response: dict, delta: dict) -> None:
    delta.pop("role", None)
    merge_fields(final_response, delta)

    tool_calls = delta.get("tool_calls")
    if tool_calls and len(tool_calls) > 0:
        index = tool_calls[0].pop("index")
        merge_fields(final_response["tool_calls"][index], tool_calls[0])


def function_to_json(func) -> dict:
    """
    Converts a Python function into a JSON-serializable dictionary
    that describes the function's signature, including its name,
    description, and parameters.

    Args:
        func: The function to be converted.

    Returns:
        A dictionary representing the function's signature in JSON format.
    """
    type_map = {
        str: "string",
        int: "integer",
        float: "number",
        bool: "boolean",
        list: "array",
        dict: "object",
        type(None): "null",
    }

    try:
        signature = inspect.signature(func)
    except ValueError as e:
        raise ValueError(
            f"Failed to get signature for function {func.__name__}: {str(e)}"
        )

    parameters = {}
    for param in signature.parameters.values():
        try:
            param_type = type_map.get(param.annotation, "string")
        except KeyError as e:
            raise KeyError(
                f"Unknown type annotation {param.annotation} for parameter {param.name}: {str(e)}"
            )
        parameters[param.name] = {"type": param_type}

    required = [
        param.name
        for param in signature.parameters.values()
        if param.default == inspect._empty
    ]

    return {
        "type": "function",
        "function": {
            "name": func.__name__,
            "description": func.__doc__ or "",
            "parameters": {
                "type": "object",
                "properties": parameters,
                "required": required,
            },
        },
    }


def function_to_jsonschema(func) -> dict:
    """
    Converts a function into a JSON Schema will be passed into Chat Completions `tools`.

    Note that most of the code is borrowed from
    https://github.com/MadcowD/ell/blob/82d626b52e5f7c72f29ecdc934e36beaaab258a3/src/ell/lmp/tool.py#L87-L119.

    ## Example

    Given the function in the following format:

    ```python
    def greet(name: str, age: int, location: str = "New York"):
        '''Greets the user. Make sure to get their name and age before calling.'''
    ```

    Rewrite it as below:

    ```python
    from pydantic import Field

    def greet(
        name: str = Field(description="The name of the person"),
        age: int = Field(description="The age of the person"),
        location: str = Field(default="New York", description="The location of the person"),
    ):
        '''Greets the user. Make sure to get their name and age before calling.'''
    ```

    Then you will get a JSON schema with per-parameter descriptions.
    """

    if hasattr(func, "__mcp_tool_schema__"):
        # If the function already has a schema, return it.
        # This is the case for tools used in MCPAgent.
        return dict(
            type="function",
            function=func.__mcp_tool_schema__
        )

    # Construct the pydantic mdoel for the _under_fn's function signature parameters.
    # 1. Get the function signature.

    sig = inspect.signature(func)

    # 2. Create a dictionary of field definitions for the Pydantic model
    fields = {}
    for param_name, param in sig.parameters.items():
        # Skip the special self argument.
        if param_name == "self":
            continue

        # Skip the special context argument.
        if param_name == __CTX_VARS_NAME__:
            continue

        # Skip *args and **kwargs
        if param.kind in (
            inspect.Parameter.VAR_POSITIONAL,
            inspect.Parameter.VAR_KEYWORD,
        ):
            continue

        # Determine the type annotation
        if param.annotation == inspect.Parameter.empty:
            raise ValueError(
                f"Parameter {param_name} has no type annotation, and cannot be converted into a tool schema for OpenAI and other provisders. Should OpenAI produce a string or an integer, etc, for this parameter?"
            )
        annotation = param.annotation

        # Determine the default value
        default = param.default

        # Check if the parameter has a Field with description
        if isinstance(param.default, FieldInfo):
            field = param.default
            fields[param_name] = (annotation, field)
        elif param.default != inspect.Parameter.empty:
            fields[param_name] = (annotation, param.default)
        else:
            # If no default value, use Field without default
            fields[param_name] = (annotation, Field(...))

    # 3. Create the Pydantic model
    model_name = f"{func.__name__}"
    ParamsModel = create_model(model_name, **fields)
    return dict(
        type="function",
        function=dict(
            name=func.__name__,
            description=func.__doc__ or "",
            parameters=ParamsModel.model_json_schema(),
        ),
    )


def handoff(triage_agent, *agents, transfer_back: bool = True):
    """
    Transfer the conversation from triage_agent to candidate agents.

    Args:
        triage_agent: The agent that will transfer the conversation.
        agents: The candidate agents that might handle the conversation next.
    """

    def transfer_back_to_triage():
        """Call this if the user brings up a topic outside your purview, including escalating to human."""
        return triage_agent

    for agent in agents:
        transfer_to = lambda: agent
        transfer_to.__name__ = agent.name
        triage_agent.functions.append(transfer_to)

        if transfer_back:
            agent.functions.append(transfer_back_to_triage)


def normalize_function_result(result: Any) -> ChatMessage:
    if isinstance(result, ChatMessage):
        return result
    return ChatMessage(role="assistant", content=str(result))

# File: .//coagent/agents/aswarm/repl/repl.py
import json

from swarm import Swarm


def process_and_print_streaming_response(response):
    content = ""
    last_sender = ""

    for chunk in response:
        if "sender" in chunk:
            last_sender = chunk["sender"]

        if "content" in chunk and chunk["content"] is not None:
            if not content and last_sender:
                print(f"\033[94m{last_sender}:\033[0m", end=" ", flush=True)
                last_sender = ""
            print(chunk["content"], end="", flush=True)
            content += chunk["content"]

        if "tool_calls" in chunk and chunk["tool_calls"] is not None:
            for tool_call in chunk["tool_calls"]:
                f = tool_call["function"]
                name = f["name"]
                if not name:
                    continue
                print(f"\033[94m{last_sender}: \033[95m{name}\033[0m()")

        if "delim" in chunk and chunk["delim"] == "end" and content:
            print()  # End of response message
            content = ""

        if "response" in chunk:
            return chunk["response"]


def pretty_print_messages(messages) -> None:
    for message in messages:
        if message["role"] != "assistant":
            continue

        # print agent name in blue
        print(f"\033[94m{message['sender']}\033[0m:", end=" ")

        # print response, if any
        if message["content"]:
            print(message["content"])

        # print tool calls in purple, if any
        tool_calls = message.get("tool_calls") or []
        if len(tool_calls) > 1:
            print()
        for tool_call in tool_calls:
            f = tool_call["function"]
            name, args = f["name"], f["arguments"]
            arg_str = json.dumps(json.loads(args)).replace(":", "=")
            print(f"\033[95m{name}\033[0m({arg_str[1:-1]})")


def run_demo_loop(
    starting_agent, client=None, context_variables=None, stream=False, debug=False
) -> None:
    client = client or Swarm()
    print("Starting Swarm CLI 🐝")

    messages = []
    agent = starting_agent

    while True:
        user_input = input("\033[90mUser\033[0m: ")
        messages.append({"role": "user", "content": user_input})

        response = client.run(
            agent=agent,
            messages=messages,
            context_variables=context_variables or {},
            stream=stream,
            debug=debug,
        )

        if stream:
            response = process_and_print_streaming_response(response)
        else:
            pretty_print_messages(response.messages)

        messages.extend(response.messages)
        agent = response.agent

# File: .//coagent/agents/aswarm/repl/__init__.py
from .repl import run_demo_loop

# File: .//coagent/agents/aswarm/__init__.py
from .core import Swarm
from .types import Agent, Response

__all__ = ["Swarm", "Agent", "Response"]

# File: .//coagent/agents/aswarm/core.py
# Standard library imports
import copy
import json
from collections import defaultdict
from typing import Any, AsyncIterator, List, Callable, Union

# Package/library imports
from openai.types.chat import ChatCompletionChunk
from openai.types.chat.chat_completion_chunk import Choice, ChoiceDelta
from coagent.agents.messages import ChatMessage
from coagent.agents.model_client import ModelClient
from coagent.core.agent import is_async_iterator
from coagent.core.util import get_func_args, pretty_trace_tool_call


# Local imports
from .util import (
    function_to_jsonschema,
    debug_print,
    merge_chunk,
    __CTX_VARS_NAME__,
    normalize_function_result,
)
from .types import (
    Agent,
    AgentFunction,
    ChatCompletionMessage,
    ChatCompletionMessageToolCall,
    Function,
    Response,
    Result,
)


class Swarm:
    def __init__(self, client: ModelClient):
        self.client: ModelClient = client

    async def get_chat_completion(
        self,
        agent: Agent,
        history: List,
        context_variables: dict,
        model_override: str,
        stream: bool,
        debug: bool,
        response_format: dict | None = None,
    ) -> ChatCompletionMessage:
        context_variables = defaultdict(str, context_variables)
        instructions = (
            agent.instructions(context_variables)
            if callable(agent.instructions)
            else agent.instructions
        )
        messages = [{"role": "system", "content": instructions}] + history
        debug_print(debug, "Getting chat completion for...:", messages)

        tools = [function_to_jsonschema(f) for f in agent.functions]
        # hide context_variables from model
        for tool in tools:
            params = tool["function"]["parameters"]
            params["properties"].pop(__CTX_VARS_NAME__, None)
            if __CTX_VARS_NAME__ in params.get("required", []):
                params["required"].remove(__CTX_VARS_NAME__)

        create_params = {
            "model": model_override or agent.model,
            "messages": messages,
            "response_format": response_format,
            "tools": tools or None,
            "tool_choice": agent.tool_choice,
            "stream": stream,
        }

        # Azure OpenAI API does not support `parallel_tool_calls` until 2024-08-01-preview.
        # See https://learn.microsoft.com/en-us/azure/ai-services/openai/api-version-deprecation#changes-between-2024-09-01-preview-and-2024-08-01-preview.
        #
        # if tools:
        #    create_params["parallel_tool_calls"] = agent.parallel_tool_calls

        # Azure OpenAI API does not support `refusal` and null `function_call`.
        for p in create_params["messages"]:
            fc = p.get("function_call", "")
            if fc is None:
                p.pop("function_call", None)
            p.pop("refusal", None)

            p.pop("reasoning_content", None)  # Remove possible reasoning content.

        try:
            response = await self.client.acompletion(**create_params)
            async for chunk in response:
                yield chunk
        except Exception as exc:
            # Return the error in form of a completion chunk.
            model = create_params["model"]
            chunk = ChatCompletionChunk(
                id="0",
                choices=[
                    Choice(
                        delta=ChoiceDelta(
                            role="assistant",
                            content=f"Failed to chat with {model}: {exc}",
                        ),
                        finish_reason="stop",
                        index=0,
                    )
                ],
                created="0",
                model=model,
                object="chat.completion.chunk",
            )
            yield chunk

    def handle_function_result(self, result, debug) -> Result:
        match result:
            case Result() as result:
                return result

            case Agent() as agent:
                return Result(
                    value=json.dumps({"assistant": agent.name}),
                    agent=agent,
                )
            case ChatMessage() as msg:
                return Result(
                    value=msg.content,
                    # add possible ctx vars
                    # context_variables={},
                )
            case _:
                try:
                    return Result(value=str(result))
                except Exception as e:
                    error_message = f"Failed to cast response to string: {result}. Make sure agent functions return a string or Result object. Error: {str(e)}"
                    debug_print(debug, error_message)
                    raise TypeError(error_message)

    async def handle_tool_calls(
        self,
        tool_calls: List[ChatCompletionMessageToolCall],
        functions: List[AgentFunction],
        context_variables: dict,
        debug: bool,
    ) -> AsyncIterator[Response | ChatMessage]:
        function_map = {f.__name__: f for f in functions}
        partial_response = Response(messages=[], agent=None, context_variables={})

        for tool_call in tool_calls:
            name = tool_call.function.name
            # handle missing tool case, skip to next tool
            if name not in function_map:
                debug_print(debug, f"Tool {name} not found in function map.")
                partial_response.messages.append(
                    {
                        # OpenAI seems to support only `role`, `tool_call_id` and `content`.
                        # See https://platform.openai.com/docs/guides/function-calling.
                        #
                        # Azure OpenAI supports one more parameter `name`.
                        # See https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling.
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": name,
                        "content": f"Error: Tool {name} not found.",
                    }
                )
                continue
            args = json.loads(tool_call.function.arguments or "{}")
            debug_print(debug, f"Processing tool call: {name} with arguments {args}")
            pretty_trace_tool_call(f"Initial Call: {name}", args)

            func = function_map[name]
            want_arg_names = get_func_args(func)
            args = {k: v for k, v in args.items() if k in want_arg_names}
            pretty_trace_tool_call(f"Actual Call: {name}", args)

            # pass context_variables to agent functions
            if __CTX_VARS_NAME__ in want_arg_names:
                args[__CTX_VARS_NAME__] = context_variables
            function_result = func(**args)

            if is_async_iterator(function_result):
                # NOTE(luopeng)
                #
                # If the function returns an async iterator, we assume that
                # the function is actually a sub-agent, then we should return
                # the stream directly to the user.
                #
                # Note that this only works if there's one tool call in the batch.
                async for chunk in function_result:
                    yield normalize_function_result(chunk)
                return

            # Non-streaming results are handled here.
            raw_result = normalize_function_result(await function_result)
            if raw_result.to_user:
                # Return the reply directly to the user.
                yield raw_result

            result: Result = self.handle_function_result(raw_result, debug)
            partial_response.messages.append(
                {
                    # OpenAI seems to support only `role`, `tool_call_id` and `content`.
                    # See https://platform.openai.com/docs/guides/function-calling.
                    #
                    # Azure OpenAI supports one more parameter `name`.
                    # See https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/function-calling.
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": name,
                    "content": result.value,
                }
            )
            partial_response.context_variables.update(result.context_variables)
            if result.agent:
                partial_response.agent = result.agent

        yield partial_response

    async def run_and_stream(
        self,
        agent: Agent,
        messages: List,
        response_format: dict | None = None,
        context_variables: dict = {},
        model_override: str = None,
        debug: bool = False,
        max_turns: int = float("inf"),
        execute_tools: bool = True,
    ) -> AsyncIterator[dict | ChatMessage]:
        active_agent = agent
        context_variables = copy.deepcopy(context_variables)
        history = copy.deepcopy(messages)
        init_len = len(messages)

        while len(history) - init_len < max_turns:
            message = {
                "content": "",
                "reasoning_content": "",
                # No `sender` param is supported by model
                # "sender": agent.name,
                "role": "assistant",
                "function_call": None,
                "tool_calls": defaultdict(
                    lambda: {
                        "function": {"arguments": "", "name": ""},
                        "id": "",
                        "type": "",
                    }
                ),
            }

            # get completion with current history, agent
            completion = self.get_chat_completion(
                agent=active_agent,
                history=history,
                response_format=response_format,
                context_variables=context_variables,
                model_override=model_override,
                stream=True,
                debug=debug,
            )

            yield {"delim": "start"}
            async for chunk in completion:
                delta = json.loads(chunk.choices[0].delta.json())
                if delta["role"] == "assistant":
                    delta["sender"] = active_agent.name

                delta_content = delta.get("content") or ""
                delta_reasoning_content = delta.get("reasoning_content") or ""
                if delta_content or delta_reasoning_content:
                    yield ChatMessage(
                        role=delta["role"] or "assistant",
                        content=delta_content,
                        reasoning_content=delta_reasoning_content,
                    )

                delta.pop("role", None)
                delta.pop("sender", None)
                merge_chunk(message, delta)
            yield {"delim": "end"}

            message["tool_calls"] = list(message.get("tool_calls", {}).values())
            if not message["tool_calls"]:
                message.pop("tool_calls", None)
            debug_print(debug, "Received completion:", message)
            history.append(message)

            if not message.get("tool_calls") or not execute_tools:
                debug_print(debug, "Ending turn.")
                break

            # convert tool_calls to objects
            tool_calls = []
            for tool_call in message["tool_calls"]:
                function = Function(
                    arguments=tool_call["function"]["arguments"],
                    name=tool_call["function"]["name"],
                )
                tool_call_object = ChatCompletionMessageToolCall(
                    id=tool_call["id"], function=function, type=tool_call["type"]
                )
                tool_calls.append(tool_call_object)

            # handle function calls, updating context_variables, and switching agents
            partial_response_or_iterator = self.handle_tool_calls(
                tool_calls, active_agent.functions, context_variables, debug
            )

            # partial_response is not a real stream response.
            is_real_stream_response = False
            async for chunk in partial_response_or_iterator:
                if isinstance(chunk, Response):
                    # If chunk is a Response object, update history and context_variables,
                    # and switch active_agent to try the next turn of the conversation.
                    partial_response = chunk

                    history.extend(partial_response.messages)
                    context_variables.update(partial_response.context_variables)
                    if partial_response.agent:
                        active_agent = partial_response.agent

                    # Just break the `async for` loop since there should only be one non-stream partial response.
                    break
                else:
                    is_real_stream_response = True
                    # If chunk is a normal ChatMessage, return it directly to the user.
                    yield chunk

            if is_real_stream_response:
                return

        yield {
            "response": Response(
                messages=history[init_len:],
                agent=active_agent,
                context_variables=context_variables,
            )
        }

    async def run(
        self,
        agent: Agent,
        messages: List,
        context_variables: dict = {},
        model_override: str = None,
        stream: bool = False,
        debug: bool = False,
        max_turns: int = float("inf"),
        execute_tools: bool = True,
    ) -> Response | AsyncIterator[dict[str, Any]]:
        if stream:
            return self.run_and_stream(
                agent=agent,
                messages=messages,
                context_variables=context_variables,
                model_override=model_override,
                debug=debug,
                max_turns=max_turns,
                execute_tools=execute_tools,
            )
        active_agent = agent
        context_variables = copy.deepcopy(context_variables)
        history = copy.deepcopy(messages)
        init_len = len(messages)

        while len(history) - init_len < max_turns and active_agent:
            # get completion with current history, agent
            completion = await self.get_chat_completion(
                agent=active_agent,
                history=history,
                context_variables=context_variables,
                model_override=model_override,
                stream=stream,
                debug=debug,
            )
            message = completion.choices[0].message
            debug_print(debug, "Received completion:", message)
            # No `sender` param is supported by model
            # message.sender = active_agent.name
            msg = json.loads(message.model_dump_json())
            # Azure OpenAI API does not support empty `tool_calls` and `audio`.
            tc = msg.get("tool_calls")
            if not tc:
                msg.pop("tool_calls", None)
            msg.pop("audio", None)
            history.append(msg)  # to avoid OpenAI types (?)

            if not message.tool_calls or not execute_tools:
                debug_print(debug, "Ending turn.")
                break

            # handle function calls, updating context_variables, and switching agents
            partial_response = await self.handle_tool_calls(
                message.tool_calls, active_agent.functions, context_variables, debug
            )
            history.extend(partial_response.messages)
            context_variables.update(partial_response.context_variables)
            if partial_response.agent:
                active_agent = partial_response.agent

        return Response(
            messages=history[init_len:],
            agent=active_agent,
            context_variables=context_variables,
        )

# File: .//coagent/agents/aswarm/types.py
from openai.types.chat import ChatCompletionMessage
from openai.types.chat.chat_completion_message_tool_call import (
    ChatCompletionMessageToolCall,
    Function,
)
from typing import List, Callable, Union, Optional

# Third-party imports
from pydantic import BaseModel

AgentFunction = Callable[[], Union[str, "Agent", dict]]


class Agent(BaseModel):
    name: str = "Agent"
    model: str = "gpt-4o"
    instructions: Union[str, Callable[[], str]] = "You are a helpful agent."
    functions: List[AgentFunction] = []
    tool_choice: str = None
    parallel_tool_calls: bool = True


class Response(BaseModel):
    messages: List = []
    agent: Optional[Agent] = None
    context_variables: dict = {}


class Result(BaseModel):
    """
    Encapsulates the possible return values for an agent function.

    Attributes:
        value (str): The result value as a string.
        agent (Agent): The agent instance, if applicable.
        context_variables (dict): A dictionary of context variables.
    """

    value: str = ""
    agent: Optional[Agent] = None
    context_variables: dict = {}

# File: .//coagent/agents/chat_agent.py
from __future__ import annotations

import functools
import inspect
import json
import re
from typing import Any, AsyncIterator, Callable

from coagent.core import Address, BaseAgent, Context, handler, logger
from pydantic_core import PydanticUndefined
from pydantic.fields import FieldInfo

from .aswarm import Agent as SwarmAgent, Swarm
from .aswarm.util import function_to_jsonschema
from .messages import ChatMessage, ChatHistory, StructuredOutput
from .model_client import default_model_client, ModelClient
from .util import is_user_confirmed


class RunContext(dict):
    """RunContext holds a dictionary of context variables that are available to all tools of a running agent."""

    @property
    def user_confirmed(self) -> bool:
        return self.get("user_confirmed", False)

    @user_confirmed.setter
    def user_confirmed(self, value: bool) -> None:
        self["user_confirmed"] = value

    @property
    def user_submitted(self) -> bool:
        return self.get("user_submitted", False)

    @user_submitted.setter
    def user_submitted(self, value: bool) -> None:
        self["user_submitted"] = value


def confirm(template: str):
    """Decorator to ask the user to confirm, if not yet, by sending a message
    which will be constructed from the given template.
    """

    def wrapper(func):
        @functools.wraps(func)
        async def run(*args: Any, **kwargs: Any) -> ChatMessage | str:
            # Ask the user to confirm if not yet.
            ctx = kwargs.get("ctx", None)
            if ctx and not RunContext(ctx).user_confirmed:
                # We assume that all meaningful arguments (includes `ctx` but
                # excepts possible `self`) are keyword arguments. Therefore,
                # here we use kwargs directly as the template variables.
                return ChatMessage(
                    role="assistant",
                    content=template.format(**kwargs),
                    type="confirm",
                    to_user=True,
                )

            # Note that we assume that the tool is not an async generator,
            # so we always use `await` here.
            return await func(*args, **kwargs)

        return run

    return wrapper


def submit(template: str = ""):
    """Decorator to ask the user to fill in the input form, if not yet, by
    sending a message which holds the input schema of the current tool.
    """
    template = (
        template
        or """\
Please fill in the input form below:

```schema
{schema}
```

```input
{input}
```\
"""
    )

    def wrapper(func):
        @functools.wraps(func)
        async def run(*args: Any, **kwargs: Any) -> ChatMessage | str:
            # Ask the user to fill in the input form if not yet.
            ctx = kwargs.get("ctx", None)
            if ctx and not RunContext(ctx).user_submitted:
                raw = function_to_jsonschema(func)
                schema_json = json.dumps(raw["function"], ensure_ascii=False, indent=2)
                # We assume that all meaningful arguments (includes `ctx` but
                # excepts possible `self`) are keyword arguments. Therefore,
                # here we use kwargs directly as the template variables.
                input_ = {k: v for k, v in kwargs.items() if k != "ctx"}
                input_json = json.dumps(input_, ensure_ascii=False, indent=2)

                return ChatMessage(
                    role="assistant",
                    content=template.format(schema=schema_json, input=input_json),
                    type="submit",
                    to_user=True,
                )

            # Note that we assume that the tool is not an async generator,
            # so we always use `await` here.
            return await func(*args, **kwargs)

        return run

    return wrapper


class Delegate:
    """A delegate agent that helps to handle a specific task."""

    def __init__(self, host_agent: ChatAgent, agent_type: str):
        self.host_agent: ChatAgent = host_agent
        self.agent_type: str = agent_type

    async def handle(self, msg: ChatHistory) -> AsyncIterator[ChatMessage]:
        addr = Address(name=self.agent_type, id=self.host_agent.address.id)
        result = await self.host_agent.channel.publish(addr, msg.encode(), stream=True)
        full_content = ""
        async for chunk in result:
            resp = ChatMessage.decode(chunk)
            if not resp.sender:
                # Set the sender to the current agent if not specified.
                resp.sender = self.agent_type
            yield resp
            full_content += resp.content
        # FIXME: no need to save message if user always provide the complete chat history.
        # msg.messages.append(ChatMessage(role="assistant", content=full_content))


def tool(func):
    """Decorator to mark the given function as a Coagent tool."""
    func.is_tool = True
    return func


def wrap_error(func):
    """Decorator to capture and return the possible error when running the given tool."""

    @functools.wraps(func)
    async def run(*args: Any, **kwargs: Any) -> ChatMessage | str:
        try:
            # Fill in the missing arguments with default values if possible.
            #
            # Note that we assume that all meaningful arguments (includes `ctx`
            # but excepts possible `self`) are keyword arguments.
            sig = inspect.signature(func)
            for name, param in sig.parameters.items():
                if name not in kwargs and isinstance(param.default, FieldInfo):
                    default = param.default.default
                    if default is PydanticUndefined:
                        raise ValueError(f"Missing required argument {name!r}")
                    else:
                        kwargs[name] = default

            # Note that we assume that the tool is not an async generator,
            # so we always use `await` here.
            return await func(*args, **kwargs)
        except Exception as exc:
            logger.exception(exc)
            return f"Error: {exc}"

    return run


class ChatAgent(BaseAgent):
    def __init__(
        self,
        name: str = "",
        system: str = "",
        tools: list[Callable] | None = None,
        client: ModelClient = default_model_client,
    ):
        super().__init__()

        self._name = name
        self._system = system
        self._client = client

        tools = tools or []
        methods = inspect.getmembers(self, predicate=inspect.ismethod)
        for _name, meth in methods:
            if getattr(meth, "is_tool", False):
                tools.append(meth)

        self._swarm_client = Swarm(self.client)

        self._swarm_agent = SwarmAgent(
            name=self.name,
            model=self.client.model,
            instructions=self.system,
            functions=[wrap_error(t) for t in tools],
        )

        self._history: ChatHistory = ChatHistory(messages=[])

    @property
    def name(self) -> str:
        if self._name:
            return self._name

        n = self.__class__.__name__
        return re.sub("([a-z0-9])([A-Z])", r"\1_\2", n).lower()

    @property
    def system(self) -> str:
        """The system instruction for this agent."""
        return self._system

    @property
    def client(self) -> ModelClient:
        return self._client

    async def get_swarm_agent(self) -> SwarmAgent:
        return self._swarm_agent

    async def agent(self, agent_type: str) -> AsyncIterator[ChatMessage]:
        """The candidate agent to delegate the conversation to."""
        async for chunk in Delegate(self, agent_type).handle(self._history):
            yield chunk

    @handler
    async def handle_history(
        self, msg: ChatHistory, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        response = self._handle_history(msg)
        async for resp in response:
            yield resp

    @handler
    async def handle_message(
        self, msg: ChatMessage, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        history = ChatHistory(messages=[msg])
        response = self._handle_history(history)
        async for resp in response:
            yield resp

    @handler
    async def handle_structured_output(
        self, msg: StructuredOutput, ctx: Context
    ) -> AsyncIterator[ChatMessage]:
        match msg.input:
            case ChatMessage():
                history = ChatHistory(messages=[msg.input])
                response = self._handle_history(history, msg.output_schema)
                async for resp in response:
                    yield resp
            case ChatHistory():
                response = self._handle_history(msg.input, msg.output_schema)
                async for resp in response:
                    yield resp

    async def _handle_history(
        self,
        msg: ChatHistory,
        response_format: dict | None = None,
    ) -> AsyncIterator[ChatMessage]:
        # For now, we assume that the agent is processing messages sequentially.
        self._history: ChatHistory = msg

        await self.update_user_confirmed(msg)
        await self.update_user_submitted(msg)

        swarm_agent = await self.get_swarm_agent()

        response = self._swarm_client.run_and_stream(
            agent=swarm_agent,
            messages=[m.model_dump() for m in msg.messages],
            response_format=response_format,
            context_variables=msg.extensions,
        )
        async for resp in response:
            if isinstance(resp, ChatMessage) and resp.has_content:
                yield resp

    async def update_user_confirmed(self, history: ChatHistory) -> None:
        ctx = RunContext(history.extensions)
        user_confirmed = ctx.user_confirmed
        is_reply_to_confirm_message = await self._has_confirm_message(history)

        if user_confirmed:
            if not is_reply_to_confirm_message:
                user_confirmed = False
        else:
            if is_reply_to_confirm_message:
                user_confirmed = await is_user_confirmed(
                    history.messages[-1].content, self.client
                )

        ctx.user_confirmed = user_confirmed
        history.extensions = ctx

    async def _has_confirm_message(self, history: ChatHistory) -> bool:
        """Check if the penultimate message is a confirmation message."""
        return len(history.messages) > 1 and history.messages[-2].type == "confirm"

    async def update_user_submitted(self, history: ChatHistory) -> None:
        ctx = RunContext(history.extensions)
        ctx.user_submitted = await self._is_submit_message(history)
        history.extensions = ctx

    async def _is_submit_message(self, history: ChatHistory) -> bool:
        """Check if the last message is a user submission message."""
        if len(history.messages) == 0:
            return False
        last_msg = history.messages[-1]
        return last_msg.role == "user" and last_msg.type == "submit"

# File: .//coagent/cli/main.py
import argparse
import asyncio
import json
import uuid

import jq

from coagent.core import Address, RawMessage, set_stderr_logger
from coagent.core.exceptions import BaseError
from coagent.runtimes import NATSRuntime, HTTPRuntime


def make_msg(header: list[str], data: str) -> RawMessage:
    header = dict([h.split(":", 1) for h in header])
    content = data.encode()
    return RawMessage(header=header, content=content)


def jq_filter(data: dict, filter: str) -> str:
    return jq.compile(filter).input(data).first()


def print_msg(msg: RawMessage | None, oneline: bool, filter: str) -> None:
    if msg is None:
        return

    output = msg.encode()

    content = output.get("content")
    if content:
        # To make jq happy, we need to convert JSON bytes to Python dict.
        output["content"] = json.loads(content)

    end = "\n" if not oneline else ""
    print(jq_filter(output, filter), flush=True, end=end)


async def run(
    server: str,
    auth: str,
    address: str,
    msg: RawMessage,
    stream: bool,
    oneline: bool,
    filter: str,
):
    parts = address.split(":", 1)
    if len(parts) == 2:
        agent_type, session_id = parts
    else:
        agent_type, session_id = parts[0], uuid.uuid4().hex

    probe = True
    if agent_type == "discovery":
        # The discovery agent is a system-provided agent, which is a distributed
        # singleton and is always available.
        session_id = ""
        probe = False

    if server.startswith("nats://"):
        runtime = NATSRuntime.from_servers(server)
    elif server.startswith(("http://", "https://")):
        runtime = HTTPRuntime.from_server(server, auth)
    else:
        raise ValueError(f"Unsupported server: {server}")

    async with runtime:
        addr = Address(name=agent_type, id=session_id)
        try:
            response = await runtime.channel.publish(
                addr,
                msg,
                stream=stream,
                request=True,
                timeout=10,
                probe=probe,
            )
            if not stream:
                print_msg(response, oneline, filter)
            else:
                async for chunk in response:
                    print_msg(chunk, oneline, filter)
        except asyncio.CancelledError:
            await runtime.channel.cancel(addr)
        except BaseError as exc:
            print(f"Error: {exc}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "address",
        type=str,
        help="The address of the agent to communicate with. Format: `agent_type[:session_id]`. (e.g. `pong` or `pong:123`)",
    )
    parser.add_argument(
        "-d",
        "--data",
        type=str,
        default="",
        help="The message body in form of JSON string. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "-H", "--header", type=str, action="append", help="The message header."
    )
    parser.add_argument(
        "--stream",
        action="store_true",
        help="Whether in stream mode. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--oneline",
        action="store_true",
        help="Whether to output stream messages in one line. This option only works in stream mode. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "-F",
        "--filter",
        type=str,
        default=".",
        help="Output filter compatible with jq. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--chat",
        action="store_true",
        help="This is a shorthand for \"--stream -F '.content.content' --oneline\" used together.",
    )
    parser.add_argument(
        "--server",
        type=str,
        default="nats://localhost:4222",
        help="The runtime server address. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--auth",
        type=str,
        default="",
        help="The runtime server authentication token. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--level",
        type=str,
        default="ERROR",
        help="The logging level. (Defaults to %(default)r)",
    )
    args = parser.parse_args()

    if not args.header:
        parser.error("At least one header (-H/--header) is required.")

    if args.chat:
        args.stream = True
        args.oneline = True
        args.filter = ".content.content"

    set_stderr_logger(args.level)
    msg = make_msg(args.header, args.data)
    asyncio.run(
        run(
            args.server,
            args.auth,
            args.address,
            msg,
            args.stream,
            args.oneline,
            args.filter,
        )
    )


if __name__ == "__main__":
    main()

# File: .//coagent/cos/__init__.py

# File: .//coagent/cos/runtime.py
import asyncio
from typing import AsyncIterator, Type

from starlette.requests import Request
from starlette.responses import Response, JSONResponse
from sse_starlette.sse import EventSourceResponse

from coagent.core import (
    Address,
    AgentSpec,
    Constructor,
    DiscoveryQuery,
    DiscoveryReply,
    RawMessage,
    logger,
)
from coagent.core.exceptions import BaseError
from coagent.core.types import Runtime
from coagent.core.util import clear_queue

from coagent.cos.agent import RemoteAgent, AgentCreated


class _CosConstructor(Constructor):
    """A constructor for creating CoS agents."""

    def __init__(
        self, typ: Type, queue: asyncio.Queue, registry: dict[Address, RemoteAgent]
    ) -> None:
        super().__init__(typ)
        self.queue = queue
        self.registry = registry

    async def __post_call__(self, agent: RemoteAgent) -> None:
        logger.info(f"[CoS] Created agent {agent.id}")

        msg = AgentCreated(addr=agent.address)
        await self.queue.put(msg.encode())

        self.registry[agent.address] = agent


class CosRuntime:
    def __init__(self, runtime: Runtime):
        self._runtime: Runtime = runtime
        self._agents: dict[Address, RemoteAgent] = {}

    async def start(self):
        await self._runtime.start()

    async def stop(self):
        await self._runtime.stop()

    async def discover(self, request: Request):
        namespace: str = request.query_params.get("namespace", "")
        recursive: bool = request.query_params.get("recursive", "") == "true"
        inclusive: bool = request.query_params.get("inclusive", "") == "true"
        detailed: bool = request.query_params.get("detailed", "") == "true"

        result: RawMessage = await self._runtime.channel.publish(
            Address(name="discovery"),
            DiscoveryQuery(
                namespace=namespace,
                recursive=recursive,
                inclusive=inclusive,
                detailed=detailed,
            ).encode(),
            request=True,
            probe=False,
        )
        reply: DiscoveryReply = DiscoveryReply.decode(result)

        return JSONResponse(reply.model_dump(mode="json"))

    async def register(self, request: Request):
        data: dict = await request.json()
        name: str = data["name"]
        description: str = data["description"]

        queue: asyncio.Queue[RawMessage] = asyncio.Queue()

        spec = AgentSpec(
            name, _CosConstructor(RemoteAgent, queue, self._agents), description
        )
        await self._runtime.register(spec)

        async def event_stream() -> AsyncIterator[str]:
            try:
                while True:
                    msg = await queue.get()
                    queue.task_done()
                    yield dict(data=msg.encode_json())
            except asyncio.CancelledError:
                # Disconnected from the client.

                # Clear the queue.
                await clear_queue(queue)

                # Deregister the corresponding factory.
                await self._runtime.deregister(name)

                raise

        return EventSourceResponse(event_stream())

    async def subscribe(self, request: Request):
        data: dict = await request.json()
        addr: Address = Address.model_validate(data["addr"])

        agent: RemoteAgent = self._agents[addr]
        queue: asyncio.Queue[RawMessage] = agent.queue

        async def event_stream() -> AsyncIterator[str]:
            try:
                while True:
                    msg = await queue.get()
                    queue.task_done()
                    yield dict(data=msg.encode_json())
            except asyncio.CancelledError:
                # Disconnected from the client.

                # Delete the corresponding agent.
                await agent.delete()

                raise

        return EventSourceResponse(event_stream())

    async def publish(self, request: Request):
        data: dict = await request.json()

        addr: Address = Address.decode(data["addr"])
        msg: RawMessage = RawMessage.decode(data["msg"])
        stream: bool = data.get("stream", False)
        probe: bool = data.get("probe", True)

        await self._update_message_header_extensions(msg, request)

        if stream:
            return await self._publish_stream(addr, msg, probe=probe)
        else:
            return await self._publish(
                addr,
                msg,
                request=data.get("request", False),
                reply=data.get("reply", ""),
                timeout=data.get("timeout", 0.5),
                probe=probe,
            )

    async def _publish(
        self,
        addr: Address,
        msg: RawMessage,
        request: bool,
        reply: str,
        timeout: float,
        probe: bool,
    ):
        try:
            resp: RawMessage | None = await self._runtime.channel.publish(
                addr=addr,
                msg=msg,
                stream=False,
                request=request,
                reply=reply,
                timeout=timeout,
                probe=probe,
            )
        except BaseError as exc:
            return JSONResponse(exc.encode(mode="json"), status_code=404)
        except asyncio.CancelledError:
            # Disconnected from the client.

            # Cancel the ongoing operation.
            await self._runtime.channel.cancel(addr)

        if resp is None:
            return Response(status_code=204)
        else:
            return JSONResponse(resp.encode(mode="json"))

    async def _publish_stream(self, addr: Address, msg: RawMessage, probe: bool):
        msgs: AsyncIterator[RawMessage] = await self._runtime.channel.publish(
            addr=addr,
            msg=msg,
            stream=True,
            probe=probe,
        )

        async def event_stream() -> AsyncIterator[str]:
            try:
                async for raw in msgs:
                    yield dict(data=raw.encode_json())
            except BaseError as exc:
                yield dict(event="error", data=exc.encode_json())
            except asyncio.CancelledError:
                # Disconnected from the client.

                # Cancel the ongoing operation.
                await self._runtime.channel.cancel(addr)

        return EventSourceResponse(event_stream())

    async def _update_message_header_extensions(
        self, msg: RawMessage, request: Request
    ) -> None:
        """Update the message header extensions according to the request data."""
        pass

# File: .//coagent/cos/agent.py
import asyncio

from coagent.core.messages import (
    Message,
    GenericMessage,
)
from coagent.core.types import Address, RawMessage
from coagent.core.agent import BaseAgent, Context, handler
from coagent.core.util import clear_queue


class AgentCreated(Message):
    """A message to notify an agent is created."""

    addr: Address


class AgentDeleted(Message):
    """A message to notify an agent is deleted."""

    addr: Address


class AgentStarted(Message):
    """A message to notify an agent that it's started."""

    addr: Address


class AgentStopped(Message):
    """A message to notify an agent that it's stopped."""

    addr: Address


class RemoteAgent(BaseAgent):
    """An agent that operates remotely."""

    def __init__(self):
        super().__init__()

        self.queue: asyncio.Queue[RawMessage] = asyncio.Queue()

    async def stop(self) -> None:
        await super().stop()
        await clear_queue(self.queue)

    async def started(self) -> None:
        """This handler is called after the agent is started."""
        msg = AgentStarted(addr=self.address)
        await self.queue.put(msg.encode())

    async def stopped(self) -> None:
        """This handler is called after the agent is stopped."""
        msg = AgentStopped(addr=self.address)
        await self.queue.put(msg.encode())

    async def _handle_data_custom(self, msg: Message, ctx: Context) -> None:
        """Override the default handler to put the message into the queue."""
        await self.queue.put(msg.encode())

    @handler
    async def handle(self, msg: GenericMessage, ctx: Context) -> None:
        """Pretend to be able to handle any messages to ensure that no
        MessageDecodeError will occur in `BaseAgent.receive()`.
        """
        pass

# File: .//coagent/cos/app.py
import argparse
import asyncio
from hypercorn.asyncio import serve
from hypercorn.config import Config
from starlette.applications import Starlette
from starlette.routing import Route

from coagent.cos.runtime import CosRuntime
from coagent.core import set_stderr_logger
from coagent.runtimes import NATSRuntime, HTTPRuntime


class Application:
    def __init__(self, server: str, auth: str):
        if server.startswith("nats://"):
            runtime = NATSRuntime.from_servers(server)
        elif server.startswith(("http://", "https://")):
            runtime = HTTPRuntime.from_server(server, auth)
        else:
            raise ValueError(f"Unsupported server: {server}")
        self.runtime = CosRuntime(runtime)

    async def startup(self):
        await self.runtime.start()

    async def shutdown(self):
        await self.runtime.stop()

    @property
    def starlette(self) -> Starlette:
        routes = [
            Route(
                "/runtime/register",
                self.runtime.register,
                methods=["POST"],
            ),
            Route(
                "/runtime/channel/subscribe",
                self.runtime.subscribe,
                methods=["POST"],
            ),
            Route(
                "/runtime/channel/publish",
                self.runtime.publish,
                methods=["POST"],
            ),
        ]
        return Starlette(
            debug=True,
            routes=routes,
            on_startup=[self.startup],
            on_shutdown=[self.shutdown],
        )


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--listen",
        type=str,
        default="127.0.0.1:8000",
        help="The listen address of the CoS server. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--server",
        type=str,
        default="nats://localhost:4222",
        help="The runtime server address. (Defaults to %(default)r)",
    )
    parser.add_argument(
        "--auth",
        type=str,
        default="",
        help="The runtime server authentication token. (Defaults to %(default)r)",
    )
    args = parser.parse_args()

    set_stderr_logger()
    app = Application(args.server, args.auth).starlette

    config = Config()
    config.bind = [args.listen]
    asyncio.run(serve(app, config))
